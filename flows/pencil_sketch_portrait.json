{
  "5": {
    "inputs": {
      "text": [
        "63",
        0
      ],
      "clip": [
        "50",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "6": {
    "inputs": {
      "conditioning": [
        "5",
        0
      ]
    },
    "class_type": "ConditioningZeroOut",
    "_meta": {
      "title": "ConditioningZeroOut"
    }
  },
  "7": {
    "inputs": {
      "guidance": 10,
      "conditioning": [
        "5",
        0
      ]
    },
    "class_type": "FluxGuidance",
    "_meta": {
      "title": "FluxGuidance"
    }
  },
  "8": {
    "inputs": {
      "positive": [
        "7",
        0
      ],
      "negative": [
        "6",
        0
      ],
      "vae": [
        "55",
        0
      ],
      "pixels": [
        "17",
        0
      ]
    },
    "class_type": "InstructPixToPixConditioning",
    "_meta": {
      "title": "InstructPixToPixConditioning"
    }
  },
  "9": {
    "inputs": {
      "seed": 420760748224250,
      "steps": 12,
      "cfg": 1,
      "sampler_name": "dpmpp_2m",
      "scheduler": "beta",
      "denoise": 1,
      "model": [
        "32",
        0
      ],
      "positive": [
        "25",
        0
      ],
      "negative": [
        "8",
        1
      ],
      "latent_image": [
        "8",
        2
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "11": {
    "inputs": {
      "samples": [
        "9",
        0
      ],
      "vae": [
        "55",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "17": {
    "inputs": {
      "ckpt_name": "depth_anything_v2_vitl.pth",
      "resolution": 1024,
      "image": [
        "37",
        0
      ]
    },
    "class_type": "DepthAnythingV2Preprocessor",
    "_meta": {
      "title": "Depth Anything V2 - Relative"
    }
  },
  "25": {
    "inputs": {
      "downsampling_factor": 2,
      "downsampling_function": "area",
      "mode": "center crop (square)",
      "weight": 0.8,
      "autocrop_margin": 0.1,
      "conditioning": [
        "8",
        0
      ],
      "style_model": [
        "26",
        0
      ],
      "clip_vision": [
        "27",
        0
      ],
      "image": [
        "37",
        0
      ]
    },
    "class_type": "ReduxAdvanced",
    "_meta": {
      "title": "ReduxAdvanced"
    }
  },
  "26": {
    "inputs": {
      "style_model_name": "flux1-redux-dev.safetensors"
    },
    "class_type": "StyleModelLoader",
    "_meta": {
      "title": "Load Style Model"
    }
  },
  "27": {
    "inputs": {
      "clip_name": "sigclip_vision_patch14_384.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "32": {
    "inputs": {
      "weight": 0.9,
      "start_at": 0,
      "end_at": 1,
      "model": [
        "50",
        0
      ],
      "pulid_flux": [
        "33",
        0
      ],
      "eva_clip": [
        "34",
        0
      ],
      "face_analysis": [
        "35",
        0
      ],
      "image": [
        "37",
        0
      ]
    },
    "class_type": "ApplyPulidFlux",
    "_meta": {
      "title": "Apply PuLID Flux"
    }
  },
  "33": {
    "inputs": {
      "pulid_file": "pulid_flux_v0.9.1.safetensors"
    },
    "class_type": "PulidFluxModelLoader",
    "_meta": {
      "title": "Load PuLID Flux Model"
    }
  },
  "34": {
    "inputs": {},
    "class_type": "PulidFluxEvaClipLoader",
    "_meta": {
      "title": "Load Eva Clip (PuLID Flux)"
    }
  },
  "35": {
    "inputs": {
      "provider": "CPU"
    },
    "class_type": "PulidFluxInsightFaceLoader",
    "_meta": {
      "title": "Load InsightFace (PuLID Flux)"
    }
  },
  "36": {
    "inputs": {
      "filename_prefix": "pencil-sketch/img",
      "images": [
        "51",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "37": {
    "inputs": {
      "upscale_method": "lanczos",
      "megapixels": 1,
      "image": [
        "47",
        0
      ]
    },
    "class_type": "ImageScaleToTotalPixels",
    "_meta": {
      "title": "Scale Image to Total Pixels"
    }
  },
  "40": {
    "inputs": {
      "state": true,
      "display_name": "Use Gemini instead of Ollama",
      "optional": true,
      "advanced": true,
      "order": 95,
      "custom_id": "vision_provider",
      "hidden": false,
      "input_off_state": [
        "43",
        0
      ],
      "input_on_state": [
        "41",
        0
      ]
    },
    "class_type": "VixUiCheckboxLogic",
    "_meta": {
      "title": "VixUI-CheckboxLogic"
    }
  },
  "41": {
    "inputs": {
      "prompt": [
        "62",
        0
      ],
      "safety_settings": "BLOCK_NONE",
      "response_type": "text",
      "model": "gemini-2.0-flash-lite-001",
      "api_key": "",
      "proxy": "",
      "system_instruction": "",
      "error_fallback_value": "",
      "seed": 1,
      "image_1": [
        "37",
        0
      ]
    },
    "class_type": "Ask_Gemini",
    "_meta": {
      "title": "Ask Gemini"
    }
  },
  "43": {
    "inputs": {
      "query": [
        "62",
        0
      ],
      "debug": "enable",
      "url": "http://127.0.0.1:11434",
      "model": "llava:7b-v1.6-vicuna-q8_0",
      "keep_alive": 0,
      "format": "text",
      "seed": 2130378911,
      "images": [
        "37",
        0
      ]
    },
    "class_type": "OllamaVision",
    "_meta": {
      "title": "Ollama Vision"
    }
  },
  "46": {
    "inputs": {
      "name": "pencil_sketch_portrait",
      "display_name": "Pencil Sketch Portrait",
      "description": "Sketch portrait using pencil",
      "author": "Datou",
      "homepage": "https://openart.ai/workflows/datou/portrait-pencil-sketch/W0yMzpiK9dTF0p13V0JQ",
      "documentation": "",
      "license": "",
      "tags": "[\"general\", \"portrait\", \"sketch\"]",
      "version": "1.1.1",
      "requires": "[\"Ollama:llava:7b-v1.6-vicuna-q8_0\"]",
      "is_seed_supported": true,
      "is_count_supported": true,
      "is_translations_supported": false,
      "is_macos_supported": true,
      "required_memory_gb": 12,
      "hidden": false,
      "remote_vae": true
    },
    "class_type": "VixUiWorkflowMetadata",
    "_meta": {
      "title": "VixUI-WorkflowMetadata"
    }
  },
  "47": {
    "inputs": {
      "image": ""
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "input;Person's face;order=1;custom_id=person_face"
    }
  },
  "50": {
    "inputs": {
      "lora_01": "pencilbox.safetensors",
      "strength_01": 1,
      "lora_02": "flux1-depth-dev-lora.safetensors",
      "strength_02": 0.8,
      "lora_03": "FLUX.1-Turbo-Alpha.safetensors",
      "strength_03": 1,
      "lora_04": "None",
      "strength_04": 1,
      "model": [
        "59",
        0
      ],
      "clip": [
        "58",
        0
      ]
    },
    "class_type": "Lora Loader Stack (rgthree)",
    "_meta": {
      "title": "Lora Loader Stack (rgthree)"
    }
  },
  "51": {
    "inputs": {
      "state": false,
      "input_off_state": [
        "11",
        0
      ],
      "input_on_state": [
        "52",
        0
      ]
    },
    "class_type": "VixCheckboxLogic",
    "_meta": {
      "title": "remote_vae"
    }
  },
  "52": {
    "inputs": {
      "vae_type": "Flux",
      "samples": [
        "9",
        0
      ]
    },
    "class_type": "RemoteVAEDecode",
    "_meta": {
      "title": "VAE Decode (Remote)"
    }
  },
  "55": {
    "inputs": {
      "vae_name": "ae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "58": {
    "inputs": {
      "clip_name1": "t5xxl_fp16.safetensors",
      "clip_name2": "clip_l.safetensors",
      "type": "flux",
      "device": "default"
    },
    "class_type": "DualCLIPLoader",
    "_meta": {
      "title": "DualCLIPLoader"
    }
  },
  "59": {
    "inputs": {
      "unet_name": "flux1-dev.sft",
      "weight_dtype": [
        "60",
        0
      ]
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "60": {
    "inputs": {
      "default_value": "fp8_e4m3fn",
      "possible_values": "[\"default\", \"fp8_e4m3fn\", \"fp8_e4m3fn_fast\", \"fp8_e5m2\"]",
      "display_name": "Diffusion precision",
      "optional": true,
      "advanced": true,
      "order": 30,
      "custom_id": "diffusion_precision",
      "hidden": false
    },
    "class_type": "VixUiList",
    "_meta": {
      "title": "VixUI-List"
    }
  },
  "61": {
    "inputs": {
      "text": "pencil sketch, minimalist, impressionism, negative space"
    },
    "class_type": "VixMultilineText",
    "_meta": {
      "title": "Text Multiline"
    }
  },
  "62": {
    "inputs": {
      "text": "Generate a structured caption for the given image.\n\n    Detect and describe the position of all visible subjects or objects relative to the frame.\n    Provide description of the subjects, including physical appearance, attire, accessories, and expressions.\n    Detect and transcribe visible text, specifying its position and font style.\n    Conclude with the overall mood or atmosphere.\n\nDo not describe or pay attention to the background.\n\nThe description must be accurate, comprehensive, logically organized, and contain no more than 46 words.\n"
    },
    "class_type": "VixMultilineText",
    "_meta": {
      "title": "Text Multiline"
    }
  },
  "63": {
    "inputs": {
      "delimiter": ", ",
      "clean_whitespace": "true",
      "text_a": [
        "61",
        0
      ],
      "text_b": [
        "40",
        0
      ]
    },
    "class_type": "VixTextConcatenate",
    "_meta": {
      "title": "Text Concatenate"
    }
  }
}
