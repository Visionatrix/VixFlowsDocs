{
  "205": {
    "inputs": {
      "seed": 1,
      "steps": 8,
      "cfg": 2,
      "sampler_name": "dpmpp_sde",
      "scheduler": "karras",
      "denoise": [
        "479",
        0
      ],
      "preview_method": "none",
      "vae_decode": "true",
      "model": [
        "406",
        0
      ],
      "positive": [
        "406",
        1
      ],
      "negative": [
        "406",
        2
      ],
      "latent_image": [
        "389",
        3
      ],
      "optional_vae": [
        "206",
        2
      ]
    },
    "class_type": "KSampler (Efficient)",
    "_meta": {
      "title": "KSampler (Efficient)"
    }
  },
  "206": {
    "inputs": {
      "ckpt_name": "Juggernaut_RunDiffusionPhoto2_Lightning_4Steps.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "209": {
    "inputs": {
      "instantid_file": "instantid-ip-adapter.bin"
    },
    "class_type": "InstantIDModelLoader",
    "_meta": {
      "title": "Load InstantID Model"
    }
  },
  "210": {
    "inputs": {
      "control_net_name": "instantid-controlnet.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "211": {
    "inputs": {
      "provider": "CPU"
    },
    "class_type": "InstantIDFaceAnalysis",
    "_meta": {
      "title": "InstantID Face Analysis"
    }
  },
  "215": {
    "inputs": {
      "strength": 0.7000000000000001,
      "start_percent": 0,
      "end_percent": 0.4,
      "positive": [
        "224",
        0
      ],
      "negative": [
        "224",
        1
      ],
      "control_net": [
        "216",
        0
      ],
      "image": [
        "383",
        0
      ],
      "vae": [
        "206",
        2
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "216": {
    "inputs": {
      "control_net_name": "control-lora-openposeXL2-rank256.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "223": {
    "inputs": {
      "share_norm": "both",
      "share_attn": "q+k",
      "scale": 1,
      "model": [
        "206",
        0
      ]
    },
    "class_type": "StyleAlignedBatchAlign",
    "_meta": {
      "title": "StyleAligned Batch Align"
    }
  },
  "224": {
    "inputs": {
      "text": [
        "441",
        0
      ],
      "max_frames": 8,
      "print_output": false,
      "app_text": [
        "456",
        0
      ],
      "start_frame": 0,
      "end_frame": 0,
      "clip": [
        "206",
        1
      ]
    },
    "class_type": "BatchPromptSchedule",
    "_meta": {
      "title": "Batch Prompt Schedule üìÖüÖïüÖù"
    }
  },
  "225": {
    "inputs": {
      "frame_rate": 12,
      "loop_count": 0,
      "filename_prefix": "ComfyUI",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 19,
      "save_metadata": true,
      "pingpong": false,
      "save_output": true,
      "images": [
        "361",
        0
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "Video Combine üé•üÖ•üÖóüÖ¢"
    }
  },
  "226": {
    "inputs": {
      "width": [
        "483",
        0
      ],
      "height": [
        "483",
        1
      ],
      "batch_size": 8
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "232": {
    "inputs": {
      "lora_name": "sliders/professional.pt",
      "strength_model": 1,
      "model": [
        "223",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "360": {
    "inputs": {
      "lora_name": "PE_PencilDrawing.safetensors",
      "strength_model": 0.5,
      "model": [
        "232",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "361": {
    "inputs": {
      "brightness": -0.05,
      "contrast": 1.1,
      "saturation": 0.5,
      "sharpness": 1.2,
      "blur": 0,
      "gaussian_blur": 0,
      "edge_enhance": 0.3,
      "detail_enhance": "false",
      "image": [
        "407",
        0
      ]
    },
    "class_type": "Image Filter Adjustments",
    "_meta": {
      "title": "Image Filter Adjustments"
    }
  },
  "378": {
    "inputs": {
      "upscale_method": "lanczos",
      "megapixels": 1,
      "image": [
        "460",
        0
      ]
    },
    "class_type": "ImageScaleToTotalPixels",
    "_meta": {
      "title": "ImageScaleToTotalPixels"
    }
  },
  "383": {
    "inputs": {
      "detect_hand": "enable",
      "detect_body": "enable",
      "detect_face": "enable",
      "resolution": 512,
      "bbox_detector": "yolox_l.torchscript.pt",
      "pose_estimator": "dw-ll_ucoco_384_bs5.torchscript.pt",
      "scale_stick_for_xinsr_cn": "disable",
      "image": [
        "378",
        0
      ]
    },
    "class_type": "DWPreprocessor",
    "_meta": {
      "title": "DWPose Estimator"
    }
  },
  "385": {
    "inputs": {
      "method": "fidelity",
      "weight": 1,
      "start_at": 0,
      "end_at": 0.6,
      "model": [
        "360",
        0
      ],
      "pulid": [
        "386",
        0
      ],
      "eva_clip": [
        "387",
        0
      ],
      "face_analysis": [
        "388",
        0
      ],
      "image": [
        "378",
        0
      ]
    },
    "class_type": "ApplyPulid",
    "_meta": {
      "title": "Apply PuLID"
    }
  },
  "386": {
    "inputs": {
      "pulid_file": "ip-adapter_pulid_sdxl_fp16.safetensors"
    },
    "class_type": "PulidModelLoader",
    "_meta": {
      "title": "Load PuLID Model"
    }
  },
  "387": {
    "inputs": {},
    "class_type": "PulidEvaClipLoader",
    "_meta": {
      "title": "Load Eva Clip (PuLID)"
    }
  },
  "388": {
    "inputs": {
      "provider": "CPU"
    },
    "class_type": "InstantIDFaceAnalysis",
    "_meta": {
      "title": "InstantID Face Analysis"
    }
  },
  "389": {
    "inputs": {
      "seed": 88566838126408,
      "steps": 8,
      "cfg": 2,
      "sampler_name": "dpmpp_sde",
      "scheduler": "karras",
      "denoise": 1,
      "preview_method": "none",
      "vae_decode": "true",
      "model": [
        "385",
        0
      ],
      "positive": [
        "215",
        0
      ],
      "negative": [
        "215",
        1
      ],
      "latent_image": [
        "226",
        0
      ],
      "optional_vae": [
        "206",
        2
      ]
    },
    "class_type": "KSampler (Efficient)",
    "_meta": {
      "title": "KSampler (Efficient)"
    }
  },
  "400": {
    "inputs": {
      "number_of_faces": 1,
      "scale_factor": 4.3,
      "shift_factor": 0.45,
      "start_index": 0,
      "max_faces_per_image": 50,
      "aspect_ratio": "1:1",
      "image": [
        "482",
        0
      ]
    },
    "class_type": "AutoCropFaces",
    "_meta": {
      "title": "Auto Crop Faces"
    }
  },
  "403": {
    "inputs": {},
    "class_type": "BRIA_RMBG_ModelLoader_Zho",
    "_meta": {
      "title": "üßπBRIA_RMBG Model Loader"
    }
  },
  "404": {
    "inputs": {
      "rmbgmodel": [
        "403",
        0
      ],
      "image": [
        "400",
        0
      ]
    },
    "class_type": "BRIA_RMBG_Zho",
    "_meta": {
      "title": "üßπBRIA RMBG"
    }
  },
  "405": {
    "inputs": {
      "image": [
        "404",
        0
      ]
    },
    "class_type": "SplitImageWithAlpha",
    "_meta": {
      "title": "Split Image with Alpha"
    }
  },
  "406": {
    "inputs": {
      "weight": 1,
      "start_at": 0,
      "end_at": 1,
      "instantid": [
        "209",
        0
      ],
      "insightface": [
        "211",
        0
      ],
      "control_net": [
        "210",
        0
      ],
      "image": [
        "378",
        0
      ],
      "model": [
        "360",
        0
      ],
      "positive": [
        "224",
        0
      ],
      "negative": [
        "224",
        1
      ],
      "image_kps": [
        "389",
        5
      ]
    },
    "class_type": "ApplyInstantID",
    "_meta": {
      "title": "Apply InstantID"
    }
  },
  "407": {
    "inputs": {
      "ckpt_name": "rife47.pth",
      "clear_cache_after_n_frames": 10,
      "multiplier": 24,
      "fast_mode": true,
      "ensemble": true,
      "scale_factor": 1,
      "frames": [
        "205",
        5
      ]
    },
    "class_type": "RIFE VFI",
    "_meta": {
      "title": "RIFE VFI (recommend rife47 and rife49)"
    }
  },
  "417": {
    "inputs": {
      "text": "\"0\" :\"Three months old,litte girlÔºåbaby:2Ôºåkawaii,very short hair\",\n\"1\" :\"5-year-old,cute kid,girl\",\n\"2\" :\"16-year-old,young girl,long hair\",\n\"3\" :\"26-year-old,woman,long hair\",\n\"4\" :\"44-year-old,old woman\",\n\"5\" :\"64-year-old,old woman,gray hair\",\n\"6\" :\"84-year-old,old woman,wrinkles,white hair\",\n\"7\" :\"104-year-old,very old woman,wrinkles:2,white hair\","
    },
    "class_type": "Text Multiline (Code Compatible)",
    "_meta": {
      "title": "Female"
    }
  },
  "418": {
    "inputs": {
      "text": "\"0\" :\"Three months old,litte boyÔºåbaby:2,kawaii,very short hair\",\n\"1\" :\"5-year-old,cute boy,short hair\",\n\"2\" :\"16-year-old,handsome man\",\n\"3\" :\"26-year-old,handsome man\",\n\"4\" :\"44-year-old,old man\",\n\"5\" :\"64-year-old,old man,gray hair\",\n\"6\" :\"84-year-old,old man,wrinkles,white hair\",\n\"7\" :\"104-year-old,very old man,wrinkles:2,bald,white hair\","
    },
    "class_type": "Text Multiline",
    "_meta": {
      "title": "Male"
    }
  },
  "439": {
    "inputs": {
      "text": [
        "489",
        0
      ],
      "find": "Female",
      "replace": [
        "417",
        0
      ]
    },
    "class_type": "Text Find and Replace",
    "_meta": {
      "title": "Text Find and Replace"
    }
  },
  "441": {
    "inputs": {
      "text": [
        "439",
        0
      ],
      "find": "Male",
      "replace": [
        "418",
        0
      ]
    },
    "class_type": "Text Find and Replace",
    "_meta": {
      "title": "Text Find and Replace"
    }
  },
  "446": {
    "inputs": {
      "text": "Analyze the image and return one word for each, focusing only on the main person:  \n1. Race: Choose only from 'White', 'Black', 'Asian', 'Hispanic', 'Indian', or 'Neutral' (if unclear).\n2. Gender: Choose only from 'Male' or 'Female' (default to 'Female' if unclear). Do not use 'Neutral' for gender.\n\nPlease respond in this format:\n\"Race\": \"YourRaceHere\", \"Gender\": \"YourGenderHere\"."
    },
    "class_type": "Text Multiline",
    "_meta": {
      "title": "Text Multiline"
    }
  },
  "447": {
    "inputs": {
      "query": [
        "446",
        0
      ],
      "debug": "enable",
      "url": "http://127.0.0.1:11434",
      "model": "llava:7b-v1.6-vicuna-fp16",
      "keep_alive": 0,
      "format": "json",
      "seed": 735649772,
      "images": [
        "378",
        0
      ]
    },
    "class_type": "OllamaVision",
    "_meta": {
      "title": "Ollama Vision"
    }
  },
  "452": {
    "inputs": {
      "state": true,
      "display_name": "Use Gemini instead of Ollama",
      "optional": true,
      "advanced": true,
      "order": 95,
      "custom_id": "vision_provider",
      "hidden": false,
      "input_off_state": [
        "447",
        0
      ],
      "input_on_state": [
        "486",
        0
      ]
    },
    "class_type": "VixUiCheckboxLogic",
    "_meta": {
      "title": "VixUI-CheckboxLogic"
    }
  },
  "454": {
    "inputs": {
      "action": "append",
      "tidy_tags": "yes",
      "text_a": [
        "480",
        0
      ],
      "text_b": ", ",
      "text_c": [
        "488",
        0
      ],
      "result": "Smiling character in a White ShirtÔºåSmileÔºålooking at viewer, Asian"
    },
    "class_type": "StringFunction|pysssss",
    "_meta": {
      "title": "String Function üêç"
    }
  },
  "456": {
    "inputs": {
      "action": "append",
      "tidy_tags": "yes",
      "text_a": [
        "454",
        0
      ],
      "text_b": ", ",
      "text_c": [
        "489",
        0
      ],
      "result": "Smiling character in a White ShirtÔºåSmileÔºålooking at viewer, Asian, Female"
    },
    "class_type": "StringFunction|pysssss",
    "_meta": {
      "title": "String Function üêç"
    }
  },
  "460": {
    "inputs": {
      "upscale_method": "lanczos",
      "width": 1024,
      "height": 1024,
      "crop": "center",
      "image": [
        "405",
        0
      ]
    },
    "class_type": "ImageScale",
    "_meta": {
      "title": "Upscale Image"
    }
  },
  "479": {
    "inputs": {
      "value": 0.37,
      "display_name": "Level of similarity",
      "optional": true,
      "advanced": true,
      "min": 0.25,
      "max": 0.5,
      "step": 0.01,
      "order": 10,
      "custom_id": "similarity_level",
      "hidden": false
    },
    "class_type": "VixUiRangeFloat",
    "_meta": {
      "title": "VixUI-RangeFloat"
    }
  },
  "480": {
    "inputs": {
      "text": "Smiling character in a White ShirtÔºåSmileÔºålooking at viewer",
      "display_name": "Prompt",
      "optional": false,
      "advanced": false,
      "order": 2,
      "custom_id": "prompt",
      "hidden": false,
      "translatable": true
    },
    "class_type": "VixUiPrompt",
    "_meta": {
      "title": "VixUI-Prompt"
    }
  },
  "481": {
    "inputs": {
      "name": "all_your_life",
      "display_name": "All Your Life",
      "description": "Short video with different ages based on a photo of a person",
      "author": "Datou",
      "homepage": "https://openart.ai/workflows/datou/all-your-life-ver-12/KdNc8OnmzTieGRBkGHks",
      "documentation": "https://visionatrix.github.io/VixFlowsDocs/Flows/AllYourLife",
      "license": "",
      "tags": "[\"general\", \"portrait\", \"sketch\", \"video\"]",
      "version": "1.0.1",
      "requires": "[\"Ollama:llava:7b-v1.6-vicuna-q8_0\"]",
      "is_seed_supported": true,
      "is_count_supported": true,
      "is_translations_supported": true
    },
    "class_type": "VixUiWorkflowMetadata",
    "_meta": {
      "title": "VixUI-WorkflowMetadata"
    }
  },
  "482": {
    "inputs": {
      "image": "",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "input;Person's face;order=1"
    }
  },
  "483": {
    "inputs": {
      "image": [
        "378",
        0
      ]
    },
    "class_type": "GetImageSize+",
    "_meta": {
      "title": "üîß Get Image Size"
    }
  },
  "486": {
    "inputs": {
      "prompt": [
        "446",
        0
      ],
      "safety_settings": "BLOCK_NONE",
      "response_type": "json",
      "model": "gemini-1.5-flash-002",
      "api_key": "",
      "proxy": "",
      "system_instruction": "",
      "error_fallback_value": "",
      "image_1": [
        "378",
        0
      ]
    },
    "class_type": "Ask_Gemini",
    "_meta": {
      "title": "Ask Gemini"
    }
  },
  "487": {
    "inputs": {
      "dictionary_text": [
        "452",
        0
      ]
    },
    "class_type": "Text Dictionary Convert",
    "_meta": {
      "title": "Text Dictionary Convert"
    }
  },
  "488": {
    "inputs": {
      "key": "Race",
      "default_value": "Neutral",
      "dictionary": [
        "487",
        0
      ]
    },
    "class_type": "Text Dictionary Get",
    "_meta": {
      "title": "Text Dictionary Get"
    }
  },
  "489": {
    "inputs": {
      "key": "Gender",
      "default_value": "Female",
      "dictionary": [
        "487",
        0
      ]
    },
    "class_type": "Text Dictionary Get",
    "_meta": {
      "title": "Text Dictionary Get"
    }
  }
}
