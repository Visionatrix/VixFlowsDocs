{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Visionatrix Documentation","text":"<p>Welcome to the Visionatrix project documentation.</p> <p>Here, you will find all the information to get started and understand how the project works.</p> <p>Admin Manual:</p> <ul> <li>Installation</li> <li>Working Modes</li> <li>Command Line Options</li> <li>Environment Variables</li> </ul> <p>Flows Developing:</p> <ul> <li>Vix Workflows</li> <li>Technical Information</li> <li>ComfyUI to Vix Workflows Migration</li> <li>Models Catalog</li> <li>Gated Models</li> </ul> <p>Integrations Manual:</p> <ul> <li>Getting Started</li> </ul> <p>Common information:</p> <ul> <li>FAQ</li> <li>Hardware FAQ</li> <li>Hardware Results</li> <li>Hardware Results (Raw)</li> </ul> <p>Specialized stuff:</p> <ul> <li>How To Perform Benchmarks</li> <li>Swagger API</li> </ul>"},{"location":"faq/","title":"FAQ","text":""},{"location":"faq/#can-i-use-comfyui-which-is-included-in-visionatrix","title":"Can I use ComfyUI which is included in Visionatrix?","text":"<p>Yes, you can install your Nodes there and run ComfyUI separately without running Visionatrix.</p> <p>Also, ComfyUI is available from the Visionatrix UI or at <code>http://127.0.0.1:8188</code>.</p>"},{"location":"faq/#can-i-use-my-own-already-installed-comfyui-with-visionatrix","title":"Can I use my own already installed ComfyUI with Visionatrix?","text":"<p>By default, Visionatrix installs or expects ComfyUI to be in working directory under the <code>ComfyUI</code> folder name.</p> <p>You can also tell Visionatrix to use ComfyUI installed in a different path, by setting the <code>COMFYUI_DIR</code> environment variable.</p> <p>Also, you can set <code>comfyui_folder</code> database parameter(by using <code>set-global-setting</code> command) if you do not want to set the environment variable.</p>"},{"location":"faq/#can-i-run-it-on-multiple-gpu","title":"Can I run it on multiple GPU?","text":"<p>You can run one worker on one GPU and process tasks in parallel, take a look at Server and Worker modes.</p>"},{"location":"faq/#why-are-portrait-flows-on-runpodio-novitaai-slow","title":"Why are portrait flows on runpod.io / novita.ai slow?","text":"<p>Portrait flows on platforms like runpod.io or novita.ai often run slowly because these setups typically use Docker containers with restricted CPU instructions, causing the <code>onnxruntime</code> library to default to the slower <code>CPUExecutionProvider</code>.</p> <p>To significantly improve performance, you can set the execution provider explicitly to use GPU acceleration with CUDA. Execute the following command:</p> <pre><code>python3 -m visionatrix set-global-setting --key=\"insightface_provider\" --value=\"CUDA\"\n</code></pre> <p>This overrides the default provider, allowing the flows to leverage GPU hardware and run faster.</p> <p>Note</p> <p>To force this default behavior for Docker deployment types where using the terminal is not always convenient, you can simply set the <code>INSIGHTFACE_PROVIDER</code> environment variable to <code>CUDA</code>. This is defined for our public RunPOD template.</p>"},{"location":"hardware_faq/","title":"Hardware FAQ","text":"<p>First, you can take a look at the information in the ComfyUI repository.</p> <p>Note</p> <p>If you are using Windows and want to avoid hassles, currently, there are no alternatives to Nvidia. PyTorch is expected to release a native version for AMD for Windows soon, but until then, Nvidia is the only option.</p> <p>List of GPUs by usefulness:</p> <ol> <li>Nvidia 4090 <code>24 GB</code></li> <li>AMD 7900 XTX <code>24 GB</code></li> <li>Nvidia 3090 <code>24 GB</code></li> <li>Nvidia 4080 Super <code>16 GB</code></li> <li>Nvidia 4070 Ti Super <code>16 GB</code></li> <li>AMD RX 7900 XT <code>20 GB</code></li> <li>AMD RX 7900 GRE <code>16 GB</code></li> <li>Nvidia 4060 Ti <code>16 GB</code></li> <li>Nvidia 3060 <code>12 GB</code></li> </ol> <p>Note</p> <p>You can also look at any performance tests of hardware for ComfyUI as a reference.</p> <p>Q: Why are there no AMD cards other than AMD 7900 series on the list?</p> <p>A: ROCM (Radeon Open Compute) <code>officially</code> supports only these cards.</p> <p>Q: How much RAM is needed in the system?</p> <p>A: For normal operation, 32 GB is sufficient, but if you want to handle large resolutions with Supir Scaler Workflow, then 64 GB is recommended.</p> <p>Q: How to use 2 GPUs?</p> <p>A: The simplest way is to run 2 workers, each assigned to its own GPU, so they can process tasks in parallel.</p>"},{"location":"hardware_results/","title":"Hardware Benchmark Results Graphs","text":""},{"location":"hardware_results_raw/","title":"Hardware Test Results","text":""},{"location":"hardware_results_raw/#stable-cascade","title":"Stable Cascade","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory 1 pass 2.6 9950X-5090 2025/06/15 NORMALYes 11961 MB 1 pass 2.8 EPYC9355-6000P 2025/06/15 NORMALYes 11961 MB 1 pass 4.2 EPYC9355-6000P 2025/06/15 NORMALNo 6961 MB 1 pass 4.6 9950X-5090 2025/06/15 NORMALNo 6961 MB 1 pass 5.0 EPYC9364-6000A 2025/06/15 NORMALYes 11961 MB 1 pass 5.8 EPYC75F3-4090 2025/06/15 NORMALYes 11961 MB 1 pass 5.8 7900X-4070TiS 2025/06/10 NORMALYes 11153 MB 1 pass 7.7 9950X-7900XTX 2025/06/09 NORMALYes 11545 MB 1 pass 7.8 7900X-4070TiS 2025/06/10 NORMALNo 6961 MB 1 pass 8.5 9950X-7900XTX 2025/06/09 NORMALNo 7008 MB 1 pass 9.2 EPYC7452-3090 2025/06/13 NORMALYes 11961 MB 1 pass 10.0 EPYC7702-4000A 2025/06/11 NORMALYes 11480 MB 2 passes 6.4 EPYC9355-6000P 2025/06/15 NORMALYes 12750 MB 2 passes 7.8 9950X-5090 2025/06/15 NORMALYes 11962 MB 2 passes 8.7 EPYC9355-6000P 2025/06/15 NORMALNo 7128 MB 2 passes 11.0 9950X-5090 2025/06/15 NORMALNo 7112 MB 2 passes 12.2 EPYC9364-6000A 2025/06/15 NORMALYes 12750 MB 2 passes 16.9 EPYC75F3-4090 2025/06/15 NORMALYes 11961 MB 2 passes 19.7 7900X-4070TiS 2025/06/10 NORMALYes 11156 MB 2 passes 21.1 7900X-4070TiS 2025/06/10 NORMALNo 7065 MB 2 passes 22.8 9950X-7900XTX 2025/06/09 NORMALYes 11545 MB 2 passes 23.6 9950X-7900XTX 2025/06/09 NORMALNo 7072 MB 2 passes 28.6 EPYC7702-4000A 2025/06/11 NORMALYes 11480 MB 2 passes 29.4 EPYC7452-3090 2025/06/13 NORMALYes 11961 MB 3 passes 11.6 EPYC9355-6000P 2025/06/15 NORMALYes 13790 MB 3 passes 15.1 EPYC9355-6000P 2025/06/15 NORMALNo 7206 MB 3 passes 17.6 9950X-5090 2025/06/15 NORMALYes 11961 MB 3 passes 20.5 9950X-5090 2025/06/15 NORMALNo 7206 MB 3 passes 25.8 EPYC9364-6000A 2025/06/15 NORMALYes 12752 MB 3 passes 31.6 EPYC75F3-4090 2025/06/15 NORMALYes 11961 MB 3 passes 40.7 7900X-4070TiS 2025/06/10 NORMALYes 11248 MB 3 passes 42.0 7900X-4070TiS 2025/06/10 NORMALNo 7206 MB 3 passes 48.3 9950X-7900XTX 2025/06/09 NORMALYes 11545 MB 3 passes 49.4 9950X-7900XTX 2025/06/09 NORMALNo 7206 MB 3 passes 57.2 EPYC7702-4000A 2025/06/11 NORMALYes 11472 MB 3 passes 58.4 EPYC7452-3090 2025/06/13 NORMALYes 11961 MB"},{"location":"hardware_results_raw/#auraflow","title":"AuraFlow","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 9.8 EPYC9355-6000P 2025/06/15 NORMALYes 17790 MB default 12.4 EPYC9355-6000P 2025/06/15 NORMALNo 13742 MB default 13.8 9950X-5090 2025/06/15 NORMALYes 17790 MB default 17.8 9950X-5090 2025/06/15 NORMALNo 13742 MB default 20.1 EPYC75F3-4090 2025/06/15 NORMALYes 17790 MB default 26.7 EPYC9364-6000A 2025/06/15 NORMALYes 17790 MB default 38.8 7900X-4070TiS 2025/06/10 NORMALYes 13434 MB default 42.5 EPYC7452-3090 2025/06/13 NORMALYes 17790 MB default 43.4 7900X-4070TiS 2025/06/10 NORMALNo 13434 MB default 44.3 EPYC7702-4000A 2025/06/11 NORMALYes 16865 MB default 57.0 9950X-7900XTX 2025/06/09 NORMALYes 17061 MB default 60.1 9950X-7900XTX 2025/06/09 NORMALNo 13743 MB"},{"location":"hardware_results_raw/#ask-ai-internal","title":"Ask AI (Internal)","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory Generate prompt (gemma3:12b-it-qat) 9.7 9950X-5090 2025/06/15 NORMALYes 839 MB Generate prompt (gemma3:12b-it-qat) 10.7 EPYC9355-6000P 2025/06/15 NORMALYes 839 MB Generate prompt (gemma3:12b-it-qat) 15.1 EPYC75F3-4090 2025/06/15 NORMALYes 839 MB Generate prompt (gemma3:12b-it-qat) 15.1 EPYC9364-6000A 2025/06/15 NORMALYes 839 MB Generate prompt (gemma3:12b-it-qat) 17.7 EPYC7552-3090 2025/06/12 NORMALYes 838 MB Generate prompt (gemma3:12b-it-qat) 18.5 7900X-4070TiS 2025/06/09 NORMALYes 0 MB Generate prompt (gemma3:12b-it-qat) 19.4 9950X-5090 2025/06/15 NORMALYes 839 MB Generate prompt (gemma3:12b-it-qat) 19.6 9950X-7900XTX 2025/06/09 NORMALYes 0 MB Generate prompt (gemma3:12b-it-qat) 21.3 EPYC9355-6000P 2025/06/15 NORMALYes 839 MB Generate prompt (gemma3:12b-it-qat) 30.1 EPYC9364-6000A 2025/06/15 NORMALYes 839 MB Generate prompt (gemma3:12b-it-qat) 30.3 EPYC75F3-4090 2025/06/15 NORMALYes 839 MB Generate prompt (gemma3:12b-it-qat) 30.7 EPYC7702-4000A 2025/06/11 NORMALYes 839 MB Generate prompt (gemma3:12b-it-qat) 35.9 EPYC7552-3090 2025/06/12 NORMALYes 838 MB Generate prompt (gemma3:12b-it-qat) 37.2 7900X-4070TiS 2025/06/09 NORMALYes 0 MB Generate prompt (gemma3:12b-it-qat) 39.8 9950X-7900XTX 2025/06/09 NORMALYes 0 MB Generate prompt (gemma3:12b-it-qat) 61.7 EPYC7702-4000A 2025/06/11 NORMALYes 839 MB Generate prompt (gemma3:12b-it-qat) (unload=True) 11.5 9950X-5090 2025/06/15 NORMALYes 839 MB Generate prompt (gemma3:12b-it-qat) (unload=True) 13.0 EPYC9355-6000P 2025/06/15 NORMALYes 839 MB Generate prompt (gemma3:12b-it-qat) (unload=True) 18.5 EPYC9364-6000A 2025/06/15 NORMALYes 839 MB Generate prompt (gemma3:12b-it-qat) (unload=True) 19.4 EPYC75F3-4090 2025/06/15 NORMALYes 839 MB Generate prompt (gemma3:12b-it-qat) (unload=True) 20.9 7900X-4070TiS 2025/06/09 NORMALYes 0 MB Generate prompt (gemma3:12b-it-qat) (unload=True) 21.2 9950X-5090 2025/06/15 NORMALYes 839 MB Generate prompt (gemma3:12b-it-qat) (unload=True) 22.1 9950X-7900XTX 2025/06/09 NORMALYes 0 MB Generate prompt (gemma3:12b-it-qat) (unload=True) 23.7 EPYC9355-6000P 2025/06/15 NORMALYes 839 MB Generate prompt (gemma3:12b-it-qat) (unload=True) 23.8 EPYC7552-3090 2025/06/12 NORMALYes 838 MB Generate prompt (gemma3:12b-it-qat) (unload=True) 33.4 EPYC9364-6000A 2025/06/15 NORMALYes 839 MB Generate prompt (gemma3:12b-it-qat) (unload=True) 33.9 EPYC75F3-4090 2025/06/15 NORMALYes 839 MB Generate prompt (gemma3:12b-it-qat) (unload=True) 37.3 EPYC7702-4000A 2025/06/11 NORMALYes 839 MB Generate prompt (gemma3:12b-it-qat) (unload=True) 39.8 7900X-4070TiS 2025/06/09 NORMALYes 0 MB Generate prompt (gemma3:12b-it-qat) (unload=True) 41.3 EPYC7552-3090 2025/06/12 NORMALYes 838 MB Generate prompt (gemma3:12b-it-qat) (unload=True) 42.5 9950X-7900XTX 2025/06/09 NORMALYes 0 MB Generate prompt (gemma3:12b-it-qat) (unload=True) 67.5 EPYC7702-4000A 2025/06/11 NORMALYes 839 MB"},{"location":"hardware_results_raw/#remove-background-birefnet-lite","title":"Remove background (BiRefNet Lite)","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory Remove Background 0.2 9950X-5090 2025/06/15 NORMALYes 2637 MB Remove Background 0.3 9950X-7900XTX 2025/06/09 NORMALYes 2633 MB Remove Background 0.3 9950X-7900XTX 2025/06/09 NORMALNo 2637 MB Remove Background 0.3 EPYC9355-6000P 2025/06/15 NORMALYes 2637 MB Remove Background 0.3 EPYC9355-6000P 2025/06/15 NORMALNo 2638 MB Remove Background 0.3 7900X-4070TiS 2025/06/10 NORMALYes 2755 MB Remove Background 0.3 7900X-4070TiS 2025/06/10 NORMALNo 2755 MB Remove Background 0.3 9950X-5090 2025/06/15 NORMALNo 2638 MB Remove Background 0.4 EPYC9364-6000A 2025/06/15 NORMALYes 2639 MB Remove Background 0.6 EPYC7702-4000A 2025/06/11 NORMALYes 2638 MB Remove Background 0.6 EPYC75F3-4090 2025/06/15 NORMALYes 2639 MB Remove Background 0.7 EPYC7552-3090 2025/06/12 NORMALYes 2635 MB"},{"location":"hardware_results_raw/#remove-background-birefnet","title":"Remove background (BiRefNet)","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory Remove Background 0.3 9950X-5090 2025/06/15 NORMALYes 4027 MB Remove Background 0.4 EPYC9355-6000P 2025/06/15 NORMALYes 4027 MB Remove Background 0.4 EPYC9355-6000P 2025/06/15 NORMALNo 4028 MB Remove Background 0.4 9950X-5090 2025/06/15 NORMALNo 4028 MB Remove Background 0.5 EPYC9364-6000A 2025/06/15 NORMALYes 4028 MB Remove Background 0.5 7900X-4070TiS 2025/06/10 NORMALYes 4028 MB Remove Background 0.5 7900X-4070TiS 2025/06/10 NORMALNo 4029 MB Remove Background 0.7 EPYC75F3-4090 2025/06/15 NORMALYes 4028 MB Remove Background 0.8 EPYC7702-4000A 2025/06/11 NORMALYes 4027 MB Remove Background 0.8 9950X-7900XTX 2025/06/09 NORMALYes 4029 MB Remove Background 0.8 9950X-7900XTX 2025/06/09 NORMALNo 4028 MB Remove Background 0.8 EPYC7552-3090 2025/06/12 NORMALYes 4027 MB"},{"location":"hardware_results_raw/#supir-upscaler","title":"SUPIR Upscaler","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory 1024x1024 - 1.5x scaling 38.3 EPYC9355-6000P 2025/06/15 NORMALYes 9411 MB 1024x1024 - 1.5x scaling 38.7 EPYC9355-6000P 2025/06/15 NORMALNo 9409 MB 1024x1024 - 1.5x scaling 45.5 9950X-5090 2025/06/15 NORMALYes 9411 MB 1024x1024 - 1.5x scaling 45.5 9950X-5090 2025/06/15 NORMALNo 9409 MB 1024x1024 - 1.5x scaling 72.2 EPYC75F3-4090 2025/06/15 NORMALYes 9406 MB 1024x1024 - 1.5x scaling 73.2 EPYC9364-6000A 2025/06/15 NORMALYes 9406 MB 1024x1024 - 1.5x scaling 87.5 9950X-7900XTX 2025/06/09 NORMALNo 9408 MB 1024x1024 - 1.5x scaling 87.9 9950X-7900XTX 2025/06/09 NORMALYes 9401 MB 1024x1024 - 1.5x scaling 93.7 7900X-4070TiS 2025/06/10 NORMALYes 9408 MB 1024x1024 - 1.5x scaling 93.9 7900X-4070TiS 2025/06/10 NORMALNo 9407 MB 1024x1024 - 1.5x scaling 125.2 EPYC7552-3090 2025/06/12 NORMALYes 9405 MB 1024x1024 - 1.5x scaling 137.4 EPYC7702-4000A 2025/06/11 NORMALYes 9407 MB 1024x1024 - 2x scaling 77.0 EPYC9355-6000P 2025/06/15 NORMALYes 9415 MB 1024x1024 - 2x scaling 77.5 EPYC9355-6000P 2025/06/15 NORMALNo 9413 MB 1024x1024 - 2x scaling 91.8 9950X-5090 2025/06/15 NORMALNo 9413 MB 1024x1024 - 2x scaling 91.9 9950X-5090 2025/06/15 NORMALYes 9415 MB 1024x1024 - 2x scaling 148.3 EPYC9364-6000A 2025/06/15 NORMALYes 9410 MB 1024x1024 - 2x scaling 152.6 EPYC75F3-4090 2025/06/15 NORMALYes 9410 MB 1024x1024 - 2x scaling 188.0 9950X-7900XTX 2025/06/09 NORMALNo 9411 MB 1024x1024 - 2x scaling 188.5 9950X-7900XTX 2025/06/09 NORMALYes 9405 MB 1024x1024 - 2x scaling 196.3 7900X-4070TiS 2025/06/10 NORMALYes 9412 MB 1024x1024 - 2x scaling 203.2 7900X-4070TiS 2025/06/10 NORMALNo 9411 MB 1024x1024 - 2x scaling 261.4 EPYC7552-3090 2025/06/12 NORMALYes 9409 MB 1024x1024 - 2x scaling 289.4 EPYC7702-4000A 2025/06/11 NORMALYes 9411 MB"},{"location":"hardware_results_raw/#ghibli-portrait","title":"Ghibli Portrait","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 1.2 EPYC9355-6000P 2025/06/15 NORMALYes 12060 MB default 1.4 9950X-5090 2025/06/15 NORMALYes 12060 MB default 2.3 EPYC9355-6000P 2025/06/15 NORMALNo 8574 MB default 2.7 9950X-5090 2025/06/15 NORMALNo 8573 MB default 2.8 EPYC9364-6000A 2025/06/15 NORMALYes 12060 MB default 2.9 EPYC75F3-4090 2025/06/15 NORMALYes 12058 MB default 3.2 7900X-4070TiS 2025/06/10 NORMALYes 12058 MB default 3.2 9950X-7900XTX 2025/06/09 NORMALYes 12582 MB default 4.2 9950X-7900XTX 2025/06/09 NORMALNo 8574 MB default 4.6 7900X-4070TiS 2025/06/10 NORMALNo 8574 MB default 4.7 EPYC7702-4000A 2025/06/12 NORMALYes 12058 MB default 4.7 EPYC7552-3090 2025/06/12 NORMALYes 12060 MB"},{"location":"hardware_results_raw/#vintage-portrait","title":"Vintage Portrait","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 7.7 EPYC9355-6000P 2025/06/15 NORMALYes 12066 MB default 8.7 9950X-5090 2025/06/15 NORMALYes 12066 MB default 8.9 EPYC9355-6000P 2025/06/15 NORMALNo 8604 MB default 10.4 9950X-5090 2025/06/15 NORMALNo 8604 MB default 18.3 EPYC75F3-4090 2025/06/15 NORMALYes 12066 MB default 18.7 EPYC9364-6000A 2025/06/15 NORMALYes 12065 MB default 19.4 7900X-4070TiS 2025/06/10 NORMALYes 12066 MB default 19.7 9950X-7900XTX 2025/06/09 NORMALYes 12592 MB default 20.7 9950X-7900XTX 2025/06/09 NORMALNo 8607 MB default 20.8 7900X-4070TiS 2025/06/10 NORMALNo 8606 MB default 32.0 EPYC7702-4000A 2025/06/12 NORMALYes 12065 MB default 32.3 EPYC7552-3090 2025/06/12 NORMALYes 12066 MB"},{"location":"hardware_results_raw/#photo-stickers","title":"Photo Stickers","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 13.5 EPYC9355-6000P 2025/06/15 NORMALYes 13143 MB default 15.6 EPYC9355-6000P 2025/06/15 NORMALNo 9436 MB default 16.3 9950X-5090 2025/06/15 NORMALYes 13143 MB default 18.7 9950X-5090 2025/06/15 NORMALNo 9436 MB default 27.9 EPYC9364-6000A 2025/06/15 NORMALYes 13143 MB default 28.5 7900X-4070TiS 2025/06/10 NORMALYes 12390 MB default 30.0 9950X-7900XTX 2025/06/09 NORMALYes 13523 MB default 31.4 9950X-7900XTX 2025/06/09 NORMALNo 9437 MB default 31.6 7900X-4070TiS 2025/06/10 NORMALNo 9438 MB default 31.8 EPYC75F3-4090 2025/06/15 NORMALYes 13141 MB default 45.6 EPYC7552-3090 2025/06/12 NORMALYes 13143 MB default 45.8 EPYC7702-4000A 2025/06/12 NORMALYes 13167 MB"},{"location":"hardware_results_raw/#photo-from-1-image","title":"Photo from 1 image","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 3.5 EPYC9355-6000P 2025/06/15 NORMALYes 8913 MB default 4.2 9950X-5090 2025/06/15 NORMALYes 8913 MB default 5.1 EPYC9355-6000P 2025/06/15 NORMALNo 5310 MB default 5.9 EPYC75F3-4090 2025/06/15 NORMALYes 8913 MB default 6.7 9950X-5090 2025/06/15 NORMALNo 5310 MB default 7.0 EPYC9364-6000A 2025/06/15 NORMALYes 8913 MB default 9.8 7900X-4070TiS 2025/06/10 NORMALYes 8915 MB default 9.9 9950X-7900XTX 2025/06/09 NORMALYes 9452 MB default 11.5 9950X-7900XTX 2025/06/09 NORMALNo 5310 MB default 11.6 EPYC7552-3090 2025/06/12 NORMALYes 8913 MB default 12.1 7900X-4070TiS 2025/06/10 NORMALNo 5310 MB default 12.9 EPYC7702-4000A 2025/06/12 NORMALYes 8913 MB"},{"location":"hardware_results_raw/#hunyuandit","title":"HunyuanDiT","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 4.8 EPYC9355-6000P 2025/06/15 NORMALYes 9125 MB default 5.8 EPYC9355-6000P 2025/06/15 NORMALNo 3957 MB default 6.8 9950X-5090 2025/06/15 NORMALYes 9125 MB default 8.2 9950X-5090 2025/06/15 NORMALNo 3957 MB default 8.7 EPYC75F3-4090 2025/06/15 NORMALYes 9125 MB default 10.7 EPYC9364-6000A 2025/06/15 NORMALYes 9125 MB default 17.2 7900X-4070TiS 2025/06/11 NORMALYes 9125 MB default 19.1 EPYC7552-3090 2025/06/12 NORMALYes 9125 MB default 19.1 7900X-4070TiS 2025/06/11 NORMALNo 3957 MB default 22.8 EPYC7702-4000A 2025/06/11 NORMALYes 9125 MB default 24.3 9950X-7900XTX 2025/06/09 NORMALYes 9662 MB default 25.2 9950X-7900XTX 2025/06/09 NORMALNo 3982 MB"},{"location":"hardware_results_raw/#sd35-large","title":"SD3.5 Large","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 8.5 EPYC9355-6000P 2025/06/15 NORMALYes 28792 MB default 11.9 9950X-5090 2025/06/15 NORMALYes 28484 MB default 14.2 EPYC9355-6000P 2025/06/15 NORMALNo 16635 MB default 18.4 9950X-5090 2025/06/15 NORMALNo 16635 MB default 21.6 EPYC9364-6000A 2025/06/15 NORMALYes 28792 MB default 23.0 EPYC75F3-4090 2025/06/15 NORMALYes 22527 MB default 40.2 9950X-7900XTX 2025/06/09 NORMALYes 22839 MB default 43.6 9950X-7900XTX 2025/06/09 NORMALNo 16634 MB default 45.9 EPYC7552-3090 2025/06/12 NORMALYes 22767 MB default 47.6 7900X-4070TiS 2025/06/11 NORMALYes 13661 MB default 48.5 7900X-4070TiS 2025/06/11 NORMALNo 13678 MB default 55.0 EPYC7702-4000A 2025/06/11 NORMALYes 18287 MB"},{"location":"hardware_results_raw/#sd35-medium","title":"SD3.5 Medium","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 3.6 EPYC9355-6000P 2025/06/15 NORMALYes 17808 MB default 4.9 9950X-5090 2025/06/15 NORMALYes 17808 MB default 6.5 EPYC9355-6000P 2025/06/15 NORMALNo 10865 MB default 6.8 EPYC75F3-4090 2025/06/15 NORMALYes 17807 MB default 8.1 EPYC9364-6000A 2025/06/15 NORMALYes 17807 MB default 8.6 9950X-5090 2025/06/15 NORMALNo 10865 MB default 14.2 EPYC7552-3090 2025/06/12 NORMALYes 17808 MB default 15.9 9950X-7900XTX 2025/06/09 NORMALYes 17103 MB default 16.8 7900X-4070TiS 2025/06/11 NORMALYes 13120 MB default 17.3 EPYC7702-4000A 2025/06/11 NORMALYes 16852 MB default 18.7 7900X-4070TiS 2025/06/11 NORMALNo 10865 MB default 19.2 9950X-7900XTX 2025/06/09 NORMALNo 10865 MB"},{"location":"hardware_results_raw/#flux-lighting","title":"Flux Lighting","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory lighting 1.5 EPYC9355-6000P 2025/06/15 NORMALYes 34384 MB lighting 1.5 EPYC9355-6000P 2025/06/15 NORMALYes 23196 MB lighting 2.0 9950X-5090 2025/06/15 NORMALYes 23196 MB lighting 3.4 EPYC9364-6000A 2025/06/15 NORMALYes 34384 MB lighting 3.5 EPYC9364-6000A 2025/06/15 NORMALYes 23196 MB lighting 3.5 EPYC75F3-4090 2025/06/15 NORMALYes 21575 MB lighting 4.0 9950X-5090 2025/06/15 NORMALYes 29469 MB lighting 5.3 EPYC9355-6000P 2025/06/15 NORMALNo 12080 MB lighting 6.7 EPYC7452-3090 2025/06/13 NORMALYes 21576 MB lighting 6.8 9950X-5090 2025/06/15 NORMALNo 12080 MB lighting 7.8 9950X-7900XTX 2025/06/09 NORMALYes 21822 MB lighting 9.5 EPYC9355-6000P 2025/06/15 NORMALNo 23257 MB lighting 11.1 9950X-5090 2025/06/15 NORMALNo 23257 MB lighting 11.1 9950X-7900XTX 2025/06/09 NORMALYes 22908 MB lighting 11.3 9950X-7900XTX 2025/06/09 NORMALNo 12154 MB lighting 12.3 EPYC7702-4000A 2025/06/11 NORMALYes 17720 MB lighting 13.3 7900X-4070TiS 2025/06/10 NORMALYes 12771 MB lighting 13.7 EPYC75F3-4090 2025/06/15 NORMALYes 22572 MB lighting 14.1 9950X-7900XTX 2025/06/09 NORMALNo 22908 MB lighting 14.7 7900X-4070TiS 2025/06/10 NORMALNo 12080 MB lighting 16.7 7900X-4070TiS 2025/06/11 NORMALYes 13104 MB lighting 17.8 7900X-4070TiS 2025/06/11 NORMALNo 13143 MB lighting 24.6 EPYC7702-4000A 2025/06/11 NORMALYes 18674 MB lighting 25.1 EPYC7552-3090 2025/06/12 NORMALYes 22805 MB"},{"location":"hardware_results_raw/#pixart-sigma","title":"PixArt Sigma","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 3.3 EPYC9355-6000P 2025/06/15 NORMALYes 13200 MB default 4.8 9950X-5090 2025/06/15 NORMALYes 13200 MB default 5.7 EPYC9355-6000P 2025/06/15 NORMALNo 9282 MB default 6.1 EPYC75F3-4090 2025/06/15 NORMALYes 13200 MB default 7.1 EPYC9364-6000A 2025/06/15 NORMALYes 13200 MB default 7.6 9950X-5090 2025/06/15 NORMALNo 9282 MB default 12.2 7900X-4070TiS 2025/06/11 NORMALYes 11315 MB default 12.9 EPYC7552-3090 2025/06/12 NORMALYes 13200 MB default 13.6 EPYC7702-4000A 2025/06/11 NORMALYes 13200 MB default 15.4 7900X-4070TiS 2025/06/11 NORMALNo 9282 MB default 17.9 9950X-7900XTX 2025/06/09 NORMALYes 13736 MB default 20.4 9950X-7900XTX 2025/06/09 NORMALNo 9282 MB"},{"location":"hardware_results_raw/#flux","title":"Flux","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 9.1 EPYC9355-6000P 2025/06/15 NORMALYes 34403 MB default 9.7 EPYC9355-6000P 2025/06/15 NORMALYes 23206 MB default 13.3 9950X-5090 2025/06/15 NORMALYes 23206 MB default 13.6 EPYC9355-6000P 2025/06/15 NORMALNo 12090 MB default 14.6 9950X-5090 2025/06/15 NORMALYes 29469 MB default 17.0 EPYC9355-6000P 2025/06/15 NORMALNo 23277 MB default 18.1 9950X-5090 2025/06/15 NORMALNo 12090 MB default 20.1 EPYC75F3-4090 2025/06/15 NORMALYes 21585 MB default 21.5 9950X-5090 2025/06/15 NORMALNo 23277 MB default 23.5 EPYC9364-6000A 2025/06/15 NORMALYes 34403 MB default 23.9 EPYC9364-6000A 2025/06/15 NORMALYes 23206 MB default 32.3 EPYC75F3-4090 2025/06/15 NORMALYes 22575 MB default 39.5 EPYC7452-3090 2025/06/13 NORMALYes 21587 MB default 43.0 9950X-7900XTX 2025/06/09 NORMALYes 21832 MB default 44.9 9950X-7900XTX 2025/06/09 NORMALYes 22908 MB default 45.7 7900X-4070TiS 2025/06/10 NORMALYes 12744 MB default 46.3 7900X-4070TiS 2025/06/10 NORMALNo 12090 MB default 47.3 9950X-7900XTX 2025/06/09 NORMALNo 12165 MB default 47.9 9950X-7900XTX 2025/06/09 NORMALNo 22908 MB default 50.3 EPYC7702-4000A 2025/06/11 NORMALYes 17720 MB default 60.0 7900X-4070TiS 2025/06/11 NORMALYes 13223 MB default 61.9 EPYC7552-3090 2025/06/12 NORMALYes 22805 MB default 62.3 7900X-4070TiS 2025/06/11 NORMALNo 13158 MB default 69.2 EPYC7702-4000A 2025/06/11 NORMALYes 18674 MB"},{"location":"hardware_results_raw/#juggernaut-lite","title":"Juggernaut Lite","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory lighting 4.5 EPYC9355-6000P 2025/06/15 NORMALYes 10909 MB lighting 4.9 EPYC9355-6000P 2025/06/15 NORMALNo 5267 MB lighting 5.2 9950X-5090 2025/06/15 NORMALYes 10911 MB lighting 5.6 9950X-5090 2025/06/15 NORMALNo 5267 MB lighting 8.1 9950X-7900XTX 2025/06/09 NORMALYes 9369 MB lighting 8.5 9950X-7900XTX 2025/06/09 NORMALNo 5265 MB lighting 10.0 7900X-4070TiS 2025/06/10 NORMALYes 9885 MB lighting 10.5 EPYC9364-6000A 2025/06/15 NORMALYes 9885 MB lighting 11.0 7900X-4070TiS 2025/06/10 NORMALNo 5267 MB lighting 11.4 EPYC75F3-4090 2025/06/15 NORMALYes 9885 MB lighting 14.8 EPYC7452-3090 2025/06/13 NORMALYes 8861 MB lighting 18.1 EPYC7702-4000A 2025/06/11 NORMALYes 9885 MB"},{"location":"hardware_results_raw/#aesthetic-images","title":"Aesthetic images","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 2.2 EPYC9355-6000P 2025/06/15 NORMALYes 8835 MB default 2.8 9950X-5090 2025/06/15 NORMALYes 8835 MB default 3.1 EPYC9355-6000P 2025/06/15 NORMALNo 5302 MB default 4.0 EPYC75F3-4090 2025/06/15 NORMALYes 8835 MB default 4.0 9950X-5090 2025/06/15 NORMALNo 5302 MB default 4.7 EPYC9364-6000A 2025/06/15 NORMALYes 8835 MB default 6.9 7900X-4070TiS 2025/06/10 NORMALYes 8835 MB default 6.9 9950X-7900XTX 2025/06/09 NORMALYes 9360 MB default 7.7 9950X-7900XTX 2025/06/09 NORMALNo 5299 MB default 7.9 EPYC7452-3090 2025/06/13 NORMALYes 8834 MB default 8.1 7900X-4070TiS 2025/06/10 NORMALNo 5302 MB default 8.9 EPYC7702-4000A 2025/06/11 NORMALYes 8835 MB fast_run 0.9 EPYC9355-6000P 2025/06/15 NORMALYes 8835 MB fast_run 1.1 9950X-5090 2025/06/15 NORMALYes 8835 MB fast_run 1.7 EPYC75F3-4090 2025/06/15 NORMALYes 8835 MB fast_run 1.8 EPYC9355-6000P 2025/06/15 NORMALNo 5302 MB fast_run 1.8 EPYC9364-6000A 2025/06/15 NORMALYes 8835 MB fast_run 2.3 9950X-5090 2025/06/15 NORMALNo 5302 MB fast_run 2.5 7900X-4070TiS 2025/06/10 NORMALYes 8835 MB fast_run 2.6 9950X-7900XTX 2025/06/09 NORMALYes 9360 MB fast_run 3.1 EPYC7452-3090 2025/06/13 NORMALYes 8834 MB fast_run 3.4 EPYC7702-4000A 2025/06/11 NORMALYes 8835 MB fast_run 3.4 9950X-7900XTX 2025/06/09 NORMALNo 5299 MB fast_run 3.7 7900X-4070TiS 2025/06/10 NORMALNo 5302 MB"},{"location":"hardware_results_raw/#sdxl-lighting","title":"SDXL Lighting","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory lighting 0.7 EPYC9355-6000P 2025/06/15 NORMALYes 8914 MB lighting 0.7 9950X-5090 2025/06/15 NORMALYes 8914 MB lighting 1.0 EPYC9364-6000A 2025/06/15 NORMALYes 8913 MB lighting 1.2 EPYC75F3-4090 2025/06/15 NORMALYes 8913 MB lighting 1.4 7900X-4070TiS 2025/06/10 NORMALYes 8913 MB lighting 1.5 9950X-7900XTX 2025/06/09 NORMALYes 9452 MB lighting 1.5 EPYC9355-6000P 2025/06/15 NORMALNo 5155 MB lighting 1.9 9950X-5090 2025/06/15 NORMALNo 5155 MB lighting 1.9 EPYC7452-3090 2025/06/13 NORMALYes 8913 MB lighting 2.1 EPYC7702-4000A 2025/06/11 NORMALYes 8913 MB lighting 2.2 9950X-7900XTX 2025/06/09 NORMALNo 5192 MB lighting 2.5 7900X-4070TiS 2025/06/10 NORMALNo 5155 MB"},{"location":"hardware_results_raw/#pencil-sketch","title":"Pencil Sketch","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory lighting 4.0 EPYC9355-6000P 2025/06/15 NORMALYes 23067 MB lighting 5.5 9950X-5090 2025/06/15 NORMALYes 23067 MB lighting 7.8 EPYC9355-6000P 2025/06/15 NORMALNo 11942 MB lighting 8.7 EPYC75F3-4090 2025/06/15 NORMALYes 21451 MB lighting 9.6 EPYC9364-6000A 2025/06/15 NORMALYes 23067 MB lighting 10.1 9950X-5090 2025/06/15 NORMALNo 11942 MB lighting 18.1 EPYC7452-3090 2025/06/13 NORMALYes 21449 MB lighting 18.7 9950X-7900XTX 2025/06/09 NORMALYes 21680 MB lighting 22.1 9950X-7900XTX 2025/06/09 NORMALNo 12017 MB lighting 22.7 7900X-4070TiS 2025/06/10 NORMALYes 12837 MB lighting 24.0 7900X-4070TiS 2025/06/10 NORMALNo 11942 MB lighting 25.8 EPYC7702-4000A 2025/06/11 NORMALYes 17817 MB"},{"location":"hardware_results_raw/#sd35-large-small","title":"SD3.5 Large (Small)","text":"Type ExecutionTime (s) Hardware Test Time VRAM ModeSmart Memory GPU Memory default 7.0 EPYC9355-6000P 2025/06/15 NORMALYes 20902 MB default 9.1 9950X-5090 2025/06/15 NORMALYes 20902 MB default 10.6 EPYC9355-6000P 2025/06/15 NORMALNo 10865 MB default 13.4 9950X-5090 2025/06/15 NORMALNo 10865 MB default 13.7 EPYC75F3-4090 2025/06/15 NORMALYes 20759 MB default 14.6 EPYC9364-6000A 2025/06/15 NORMALYes 20902 MB default 29.6 7900X-4070TiS 2025/06/10 NORMALYes 13832 MB default 31.6 7900X-4070TiS 2025/06/10 NORMALNo 10865 MB default 35.2 EPYC7452-3090 2025/06/13 NORMALYes 20834 MB default 39.0 9950X-7900XTX 2025/06/09 NORMALYes 19779 MB default 41.9 EPYC7702-4000A 2025/06/11 NORMALYes 19451 MB default 42.4 9950X-7900XTX 2025/06/09 NORMALNo 10865 MB"},{"location":"how_to_benchmark/","title":"Introduction","text":"<p>Note</p> <p>For benchmarking, it's preferable to use the <code>SERVER</code> + <code>WORKER</code> modes.</p> <p>You can find the guide on how to install this configuration here.</p> <p>Assuming you have Visionatrix installed, you can proceed with benchmarking.</p> <p>You don't need to run the benchmark script on the same machine where Visionatrix is installed. Therefore, clone the Visionatrix documentation repository wherever it's convenient for you:</p> <pre><code>git clone https://github.com/Visionatrix/VixFlowsDocs.git\n</code></pre>"},{"location":"how_to_benchmark/#setting-up-a-virtual-environment-optional","title":"Setting Up a Virtual Environment (Optional)","text":"<p>It's recommended to use a virtual environment to avoid conflicts with other Python packages on your system. Here's how you can set up a virtual environment that works on macOS and Linux (assuming all necessary OS packages are installed):</p> <pre><code>cd VixFlowsDocs &amp;&amp; python3 -m venv venv &amp;&amp; source venv/bin/activate\n</code></pre> <p>This creates a new virtual environment named <code>venv</code> and activates it. You can now proceed to install the dependencies:</p> <pre><code>pip install -r requirements.txt\n</code></pre> <p>If you prefer not to use a virtual environment, you can install the dependencies directly:</p> <pre><code>cd VixFlowsDocs &amp;&amp; pip install -r requirements.txt\n</code></pre>"},{"location":"how_to_benchmark/#installing-ollama","title":"Installing Ollama","text":"<p>Since Visionatrix is starting to use LLM more and more, we decided to add Ollama tests to help people understand what they can expect.</p> <p>To install Ollama on Linux if it is not installed use:</p> <pre><code>curl -fsSL https://ollama.com/install.sh | sh\n</code></pre> <p>The tests are done with <code>gemma3:12b-it-qat</code> model.</p> <p>Please install  the model in Ollama using the commands:</p> <pre><code>ollama pull gemma3:12b-it-qat\n</code></pre>"},{"location":"how_to_benchmark/#huggingface-and-civitai-tokens","title":"HuggingFace and CivitAI tokens","text":"<p>Make sure that in the Visionatrix Settings, the Hugging Face and CivitAI tokens are present to install the following models used in the flows that are included in the benchmarks:</p> <ul> <li>Shou Xin</li> <li>StableDiffusion 3.5 Medium</li> <li>StableDiffusion 3.5 Large</li> </ul>"},{"location":"how_to_benchmark/#running-the-benchmark-script","title":"Running the Benchmark Script","text":"<p>The benchmark script is located in the <code>scripts/benchmarks</code> directory.</p> <p>You can run the script with the default parameters. The working directory doesn't matter because the script uses relative paths from its own location.</p> <p>If your Visionatrix instance does not have authentication enabled (for example, it's running in <code>DEFAULT</code> mode), simply run the script:</p> <pre><code>python3 scripts/benchmarks/benchmark.py\n</code></pre> <p>The script will prompt you to select the test suite(s) you want to run. Enter the number(s) corresponding to your choice:</p> <pre><code>Please select the test suites you want to run:\n1. SDXL Suite\n2. AURA_FLOW Suite\n3. CASCADE Suite\n4. DIT_8_BIT(FLUX 8-bit, ..) Suite\n5. DIT(Flux original, ..) Suite\n6. PORTRAITS Suite\n7. UPSCALERS Suite\n8. OTHER Suite\n9. OLLAMA 1024 tokens suite\n10. OLLAMA 2048 tokens suite\nEnter the numbers of the suites to run, separated by commas (e.g., 1,3,5): 1,2,3,4,5 or `ALL`\n</code></pre> <p>Note</p> <p>The script will automatically install the flows from the selected test suite if they are not already installed. It will start testing as soon as all flows are installed.</p> <p>Upon completion of the tests, a folder with results will appear in the <code>results</code> directory, named with the date, hardware, and test suite. For example:</p> <pre><code>results/2024-11-11-EPYC75F3-4090-SDXL/\n</code></pre> <p>Inside this folder, you will find the summary JSON file (e.g., <code>summary-2024-11-11-EPYC75F3-4090-SDXL.json</code>) and the detailed results for each flow and test case.</p> <p>The <code>benchmark.py</code> script supports resuming interrupted tests. If you run the script again for the same test suite, it will skip tests that have already been completed.</p> <p>You should set the environment variable <code>HARDWARE</code> in the format <code>\"CPU-GPU\"</code> before running the script. If you forget to set it, you can rename the results folder and summary file after the tests are complete to include your hardware specifications.</p> <p>If you want to add your results to the documentation, copy the summary JSON file to the <code>hardware_results</code> folder and open a pull request with this file.</p>"},{"location":"how_to_benchmark/#generating-hardware-results-table","title":"Generating Hardware Results Table","text":"<p>After running the benchmark and collecting results, you can generate a Markdown table summarizing the hardware test results using the <code>generate_hardware_results.py</code> script located in the <code>scripts/benchmarks</code> directory.</p> <p>First, copy the files generated by the benchmark (e.g., <code>summary-2024-11-13-YOUR_CPU-YOUR_GPU-SDXL.json</code>) to the <code>hardware_results</code> folder.</p> <p>Then, run the script to generate the <code>hardware_results.md</code> file:</p> <pre><code>python3 scripts/benchmarks/generate_hardware_results.py\n</code></pre> <p>This script will process the summary JSON files in the <code>hardware_results</code> folder and generate a Markdown table saved as <code>hardware_results.md</code>.</p>"},{"location":"how_to_benchmark/#supported-environment-variables","title":"Supported Environment Variables","text":"<p>As mentioned earlier, the <code>HARDWARE</code> variable is supported. Example usage:</p> <pre><code>HARDWARE=\"EPYC75F3-4090\" python3 scripts/benchmarks/benchmark.py\n</code></pre> <p>Another supported variable is <code>SERVER_URL</code>, for example:</p> <pre><code>SERVER_URL=\"http://192.168.1.10:8288\" python3 scripts/benchmarks/benchmark.py\n</code></pre> <p>Use this when Visionatrix is located on another machine.</p> <p>If you need to provide authentication credentials for the Visionatrix server, you can do so using the variables <code>USER_NAME</code> and <code>USER_PASSWORD</code>.</p> <p>Example usage along with <code>SERVER_URL</code>:</p> <pre><code>SERVER_URL=\"http://192.168.1.10:8288\" USER_NAME=\"admin\" USER_PASSWORD=\"admin\" python3 scripts/benchmarks/benchmark.py\n</code></pre> <p>The <code>COUNT</code> variable controls the number of tasks created for each test case. By default, it is set to <code>2</code>. You can set it to <code>1</code>, <code>3</code>, <code>4</code>, etc. The higher the number, the more accurate the hardware test will be.</p> <p>Another supported variable is <code>REMOVE_RESULTS</code>. By default, it is <code>1</code>, which means the tasks created during testing will be deleted from Visionatrix after completion. You can set it to <code>0</code> if you don't want the tasks to be deleted.</p> <p>If you have a slow internet connection and not all flows from your selected test suite are installed, you might want to set a custom value for the <code>FLOW_INSTALL_TIMEOUT</code> variable.</p> <p>By default, it is set to 2400 seconds (40 minutes). If the flow does not download within this time, the script will produce an error (but this does not cancel the flow installation; it will eventually be installed on the server).</p> <p>The variables <code>PAUSE_INTERVAL</code> (default value <code>0</code>) and <code>PAUSE_INTERVAL_AFTER_WARMUP</code> (default value <code>0</code>) control the pause time between tests.</p> <ul> <li> <p>The <code>PAUSE_INTERVAL</code> variable defines the pause time in seconds between test cases (useful if your device heats up and you want to prevent overheating).</p> </li> <li> <p>The <code>PAUSE_INTERVAL_AFTER_WARMUP</code> variable defines the interval of time to wait after the warm-up run. During the warm-up, models are loaded into memory. This pause can be useful on laptops or devices with insufficient cooling.</p> </li> </ul> <p>The <code>UNLOAD_MODELS_BEFORE_WARMUP</code> variable controls whether models are unloaded from memory before the warm-up run. By default, it is set to <code>1</code>. Setting it to <code>0</code> will skip unloading models before the warm-up.</p> <p>Warning</p> <p>Setting <code>UNLOAD_MODELS_BEFORE_WARMUP=0</code> may cause the <code>GPU Memory</code> column to be inaccurate, as models from previous flows could remain loaded in memory.</p> <p>Happy benchmarking! \ud83c\udfc6</p>"},{"location":"AdminManual/command_line_options/","title":"Command Line Options","text":"<p>Visionatrix supports a range of command-line options to manage installation, updating, execution, and configuration of the application. These options combine Visionatrix-specific functionality with many of the command-line features inherited from ComfyUI. Note that for some settings, values stored in the database or provided via environment variables take precedence over command-line arguments.</p>"},{"location":"AdminManual/command_line_options/#global-options","title":"Global Options","text":"<ul> <li><code>--verbose [LEVEL]</code>: Set the logging level.   Choices: <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>, <code>CRITICAL</code> Note: This option should be specified before the command.</li> </ul>"},{"location":"AdminManual/command_line_options/#commands-overview","title":"Commands Overview","text":"<p>Visionatrix provides the following commands:</p> <ul> <li>install: Performs cleanup and initialization.</li> <li>update: Updates Visionatrix to the latest version.</li> <li>run: Starts Visionatrix.</li> <li>install-flow: Installs a flow by name, tag, or from a file.</li> <li>create-user: Creates a new user.</li> <li>orphan-models: Removes orphan models.</li> <li>openapi: Generates OpenAPI specifications.</li> <li>list-global-settings: Lists all global settings.</li> <li>get-global-setting: Retrieves a specific global setting.</li> <li>set-global-setting: Creates or updates a global setting.</li> </ul> <p>Note: In previous versions, options such as <code>--comfyui_dir</code> could be used to specify the ComfyUI directory. In the current version, directory paths (e.g. <code>COMFYUI_DIR</code>, <code>BASE_DATA_DIR</code>) are determined by the database settings and environment variables. To override these, update the corresponding global settings or environment variables.</p>"},{"location":"AdminManual/command_line_options/#the-run-command","title":"The <code>run</code> Command","text":"<p>Starts the Visionatrix application, enabling both task processing and (optionally) the web user interface.</p>"},{"location":"AdminManual/command_line_options/#syntax","title":"Syntax","text":"<pre><code>python3 -m visionatrix [--verbose=LEVEL] run [options]\n</code></pre>"},{"location":"AdminManual/command_line_options/#visionatrix-specific-options","title":"Visionatrix-Specific Options","text":"<ul> <li> <p><code>--host=HOST</code>: Host to listen on (DEFAULT or SERVER mode).</p> <p>Info</p> <p>This corresponds to ComfyUI's <code>--listen</code> argument.</p> </li> <li> <p><code>--port=PORT</code>: Port number to bind to (used in DEFAULT or SERVER mode).</p> </li> <li><code>--server=SERVER_ADDRESS</code>: Address of the Vix Server (used in WORKER mode).</li> <li> <p><code>--mode {DEFAULT,WORKER,SERVER}</code>: Visionatrix operating mode.</p> <p>Choices: DEFAULT, WORKER, SERVER</p> </li> <li> <p><code>--ui [UI_DIR]</code>: Enables the web user interface.</p> </li> <li>When provided without a value, the default UI is enabled.</li> <li>When provided with a directory, it specifies a custom UI.</li> <li><code>--disable-device-detection</code>: Disables automatic device detection.</li> </ul> <p>Additionally, ComfyUI-specific options (except those unsupported) can be passed; these will be forwarded to ComfyUI. Unsupported ComfyUI options include:   - <code>--tls-keyfile</code>   - <code>--tls-certfile</code>   - <code>--enable-cors-header</code>   - <code>--verbose</code> (use Visionatrix\u2019s <code>--verbose</code> instead)   - <code>--dont-print-server</code>   - <code>--quick-test-for-ci</code>   - <code>--windows-standalone-build</code>   - <code>--auto-launch</code>   - <code>--disable-auto-launch</code>   - <code>--multi-user</code> (Visionatrix always supports multiple users)</p>"},{"location":"AdminManual/command_line_options/#the-install-command","title":"The <code>install</code> Command","text":"<p>Performs a clean installation by removing existing flows and reinstalling ComfyUI and related components.</p>"},{"location":"AdminManual/command_line_options/#syntax_1","title":"Syntax","text":"<pre><code>python3 -m visionatrix [--verbose=LEVEL] install\n</code></pre> <p>During installation, if a ComfyUI folder is already present, you will be prompted to confirm its removal.</p>"},{"location":"AdminManual/command_line_options/#the-update-command","title":"The <code>update</code> Command","text":"<p>Updates components such as ComfyUI, ComfyUI-Manager and custom nodes to the pinned versions that comes with this version of Visionatrix.</p>"},{"location":"AdminManual/command_line_options/#syntax_2","title":"Syntax","text":"<pre><code>python3 -m visionatrix [--verbose=LEVEL] update\n</code></pre>"},{"location":"AdminManual/command_line_options/#the-install-flow-command","title":"The <code>install-flow</code> Command","text":"<p>Installs a flow by specifying a file, flow name, or flow tag. This command is particularly useful in environments without a user interface.</p>"},{"location":"AdminManual/command_line_options/#syntax_3","title":"Syntax","text":"<pre><code>python3 -m visionatrix [--verbose=LEVEL] install-flow [options]\n</code></pre>"},{"location":"AdminManual/command_line_options/#options","title":"Options","text":"<p>You must provide one of the following:</p> <ul> <li><code>--file=FILE_PATH</code>: Path to a <code>comfyui_flow.json</code> file or a directory containing flow files.</li> <li><code>--name=FLOW_NAME</code>: A flow name mask to identify flows by their ID.</li> <li><code>--tag=TAG</code>: A flow tag mask to identify flows by tag.</li> </ul>"},{"location":"AdminManual/command_line_options/#the-create-user-command","title":"The <code>create-user</code> Command","text":"<p>Creates a new user in the Visionatrix system.</p>"},{"location":"AdminManual/command_line_options/#syntax_4","title":"Syntax","text":"<pre><code>python3 -m visionatrix [--verbose=LEVEL] create-user [options]\n</code></pre>"},{"location":"AdminManual/command_line_options/#options_1","title":"Options","text":"<ul> <li><code>--name=USERNAME</code> (required): User ID.</li> <li><code>--password=PASSWORD</code> (required): User password.</li> <li><code>--full_name=FULL_NAME</code>: Full name of the user.   Default: <code>John Doe</code></li> <li><code>--email=EMAIL</code>: User's email address.   Default: <code>user@example.com</code></li> <li><code>--admin=BOOLEAN</code>: Whether the user should be an administrator.   Default: <code>True</code></li> <li><code>--disabled=BOOLEAN</code>: Whether the account should be disabled.   Default: <code>False</code></li> </ul>"},{"location":"AdminManual/command_line_options/#the-orphan-models-command","title":"The <code>orphan-models</code> Command","text":"<p>Removes orphan models that are no longer needed by the system.</p>"},{"location":"AdminManual/command_line_options/#syntax_5","title":"Syntax","text":"<pre><code>python3 -m visionatrix [--verbose=LEVEL] orphan-models [options]\n</code></pre>"},{"location":"AdminManual/command_line_options/#options_2","title":"Options","text":"<ul> <li><code>--no-confirm</code>: Do not prompt for confirmation for each model.</li> <li><code>--dry-run</code>: Execute a trial run without actually removing models.</li> <li><code>--include-useful-models</code>: Include orphaned models that may be useful for future flows.</li> </ul>"},{"location":"AdminManual/command_line_options/#the-openapi-command","title":"The <code>openapi</code> Command","text":"<p>Generates OpenAPI specifications for the Visionatrix API, covering endpoints for flows and other features.</p>"},{"location":"AdminManual/command_line_options/#syntax_6","title":"Syntax","text":"<pre><code>python3 -m visionatrix [--verbose=LEVEL] openapi [options]\n</code></pre>"},{"location":"AdminManual/command_line_options/#options_3","title":"Options","text":"<ul> <li><code>--file=FILENAME</code>: Output filename for the OpenAPI specification.   Default: <code>openapi.json</code></li> <li><code>--indentation=SIZE</code>: Indentation size for the generated JSON.   Default: <code>2</code></li> <li><code>--flows=FLOWS</code>: Comma-separated list of flows to include in the spec.</li> <li>Use <code>*</code> to include all flows.</li> <li>An empty string (e.g., <code>--flows=\"\"</code>) will exclude flows.</li> <li><code>--skip-not-installed</code>: Skip flows that are not installed.   Default: Enabled.</li> <li><code>--exclude-base</code>: Exclude base application endpoints from the specification.</li> </ul>"},{"location":"AdminManual/command_line_options/#global-settings-commands","title":"Global Settings Commands","text":"<p>Visionatrix allows you to manage global settings directly from the command line.</p>"},{"location":"AdminManual/command_line_options/#the-list-global-settings-command","title":"The <code>list-global-settings</code> Command","text":"<p>Lists all global settings stored in the database.</p>"},{"location":"AdminManual/command_line_options/#syntax_7","title":"Syntax","text":"<pre><code>python3 -m visionatrix [--verbose=LEVEL] list-global-settings\n</code></pre> <p>This command displays each setting in the following format:</p> <pre><code> - setting_name = \"value\"\n</code></pre>"},{"location":"AdminManual/command_line_options/#the-get-global-setting-command","title":"The <code>get-global-setting</code> Command","text":"<p>Retrieves the value of a specific global setting.</p>"},{"location":"AdminManual/command_line_options/#syntax_8","title":"Syntax","text":"<pre><code>python3 -m visionatrix [--verbose=LEVEL] get-global-setting --key=SETTING_NAME\n</code></pre>"},{"location":"AdminManual/command_line_options/#the-set-global-setting-command","title":"The <code>set-global-setting</code> Command","text":"<p>Creates or updates a global setting.</p>"},{"location":"AdminManual/command_line_options/#syntax_9","title":"Syntax","text":"<pre><code>python3 -m visionatrix [--verbose=LEVEL] set-global-setting --key=SETTING_NAME --value=VALUE [--sensitive]\n</code></pre> <ul> <li>The <code>--sensitive</code> flag marks the setting as sensitive (hiding it from non-admin users).</li> </ul>"},{"location":"AdminManual/command_line_options/#examples","title":"Examples","text":""},{"location":"AdminManual/command_line_options/#running-visionatrix-with-custom-options","title":"Running Visionatrix with Custom Options","text":"<p>Start Visionatrix in SERVER mode on a specific host and port with the default Web UI:</p> <pre><code>python3 -m visionatrix --verbose=WARNING run --host=0.0.0.0 --port=8000 --ui\n</code></pre>"},{"location":"AdminManual/command_line_options/#running-visionatrix-in-worker-mode","title":"Running Visionatrix in WORKER Mode","text":"<p>Connect a worker instance to a Vix Server:</p> <pre><code>python3 -m visionatrix --verbose=INFO run --mode WORKER --server=http://your_vix_server_address\n</code></pre>"},{"location":"AdminManual/command_line_options/#installing-a-flow-from-a-file","title":"Installing a Flow from a File","text":"<p>Install a flow by providing the path to a flow JSON file:</p> <pre><code>python3 -m visionatrix install-flow --file=/path/to/comfyui_flow.json\n</code></pre>"},{"location":"AdminManual/command_line_options/#creating-a-new-user","title":"Creating a New User","text":"<p>Create a new administrator user:</p> <pre><code>python3 -m visionatrix create-user --name=admin --password=secret --email=admin@example.com\n</code></pre>"},{"location":"AdminManual/command_line_options/#removing-orphan-models","title":"Removing Orphan Models","text":"<p>Perform a dry-run cleanup of orphan models without confirmation prompts:</p> <pre><code>python3 -m visionatrix orphan-models --no-confirm --dry-run\n</code></pre>"},{"location":"AdminManual/command_line_options/#generating-openapi-specifications","title":"Generating OpenAPI Specifications","text":"<p>Generate an OpenAPI specification that includes all flows:</p> <pre><code>python3 -m visionatrix openapi --flows=\"*\" --file=openapi.json\n</code></pre>"},{"location":"AdminManual/command_line_options/#listing-global-settings","title":"Listing Global Settings","text":"<p>Display all global settings:</p> <pre><code>python3 -m visionatrix list-global-settings\n</code></pre>"},{"location":"AdminManual/command_line_options/#retrieving-a-specific-global-setting","title":"Retrieving a Specific Global Setting","text":"<p>Retrieve the value of a global setting:</p> <pre><code>python3 -m visionatrix get-global-setting --key=comfyui_folder\n</code></pre>"},{"location":"AdminManual/command_line_options/#setting-a-global-setting","title":"Setting a Global Setting","text":"<p>Update or create a global setting (marking it as sensitive if needed):</p> <pre><code>python3 -m visionatrix set-global-setting --key=comfyui_folder --value=/new/path/to/ComfyUI --sensitive\n</code></pre>"},{"location":"AdminManual/environment_variables/","title":"Environment Variables","text":"<p>In addition to the usual ways of setting environment variables, they can be set via a <code>.env</code> file. Visionatrix uses the python-dotenv package to load variables from a <code>.env</code> file.</p> <p>Additionally, some variables can also be specified via command-line arguments, which take precedence over environment variables.</p> <p>This document describes the available environment variables, their default values, and how they affect Visionatrix's operation.</p>"},{"location":"AdminManual/environment_variables/#using-a-env-file","title":"Using a <code>.env</code> File","text":"<p>To simplify configuration, you can create a <code>.env</code> file in the root directory of your Visionatrix installation. In this file, you can define environment variables in the format:</p> <pre><code>VARIABLE_NAME=value\n</code></pre>"},{"location":"AdminManual/environment_variables/#general-variables","title":"General Variables","text":""},{"location":"AdminManual/environment_variables/#comfyui_dir","title":"COMFYUI_DIR","text":"<ul> <li>Description: Directory for the folder containing ComfyUI. The path can be absolute or relative.</li> <li> <p>Default: <code>./ComfyUI</code></p> <p>Note</p> <p>The database value <code>comfyui_folder</code> takes precedence over the environment variable.</p> </li> </ul>"},{"location":"AdminManual/environment_variables/#base_data_dir","title":"BASE_DATA_DIR","text":"<ul> <li>Description: Base directory for input,output, models and user directories. The path can be absolute or relative.</li> <li> <p>Default: <code>./ComfyUI-Data</code></p> <p>Note</p> <p>The database value <code>comfyui_base_data_folder</code> takes precedence over the environment variable.</p> <p>Setting the values of <code>INPUT_DIR</code>, <code>OUTPUT_DIR</code>, <code>USER_DIR</code>, <code>MODELS_DIR</code> overrides the corresponding subdirectories and the value of <code>BASE_DATA_DIR</code> in them is no longer taken into account.</p> </li> </ul>"},{"location":"AdminManual/environment_variables/#input_dir","title":"INPUT_DIR","text":"<ul> <li>Description: Directory for input files. The path can be absolute or relative.</li> <li> <p>Default: <code>ComfyUI-Data/input</code></p> <p>Note</p> <p>The database value <code>comfyui_input_folder</code> takes precedence over the environment variable.</p> </li> </ul>"},{"location":"AdminManual/environment_variables/#output_dir","title":"OUTPUT_DIR","text":"<ul> <li>Description: Directory for output files. The path can be absolute or relative.</li> <li> <p>Default: <code>ComfyUI-Data/output</code></p> <p>Note</p> <p>The database value <code>comfyui_output_folder</code> takes precedence over the environment variable.</p> </li> </ul>"},{"location":"AdminManual/environment_variables/#user_dir","title":"USER_DIR","text":"<ul> <li>Description: Directory with user data. The path can be absolute or relative.</li> <li> <p>Default: <code>ComfyUI-Data/user</code></p> <p>Note</p> <p>The database value <code>comfyui_user_folder</code> takes precedence over the environment variable.</p> </li> </ul>"},{"location":"AdminManual/environment_variables/#models_dir","title":"MODELS_DIR","text":"<ul> <li>Description: Directory with models. The path can be absolute or relative.</li> <li> <p>Default: <code>ComfyUI-Data/models</code></p> <p>Note</p> <p>The database value <code>comfyui_models_folder</code> takes precedence over the environment variable.</p> </li> </ul>"},{"location":"AdminManual/environment_variables/#ui_dir","title":"UI_DIR","text":"<ul> <li>Description: Path to the User Interface (JavaScript frontend). This is the directory that will be served as the root of the website.</li> <li> <p>Default: Empty string.</p> <p>Note</p> <ul> <li>Command-line Argument:</li> <li><code>--ui</code> (enables the User Interface using the default frontend), or</li> <li><code>--ui=/path/to/frontend</code> (specifies the path to a custom frontend).</li> </ul> <p>Command-line arguments take precedence over the environment variable.</p> </li> </ul>"},{"location":"AdminManual/environment_variables/#vix_mode","title":"VIX_MODE","text":"<ul> <li>Description: Determines the working mode of Visionatrix.</li> <li> <p><code>DEFAULT</code>: Storage and delivery of tasks (Server) + task processing (Worker).</p> <p>Note</p> <p>Authentication is disabled in this mode.</p> </li> <li> <p><code>SERVER</code>: Only storage and management of tasks.</p> <p>Note</p> <p>Authentication is enabled. Reccomend to use a PostgreSQL database.</p> </li> <li> <p><code>WORKER</code>: Only processes tasks from the Server (client consuming mode, no backend).</p> </li> <li> <p>Default: <code>DEFAULT</code></p> <p>Note</p> <p>The command-line argument <code>--mode=</code> takes precedence over the environment variable.</p> </li> </ul> <p>Please refer to the Working Modes documentation for more details.</p>"},{"location":"AdminManual/environment_variables/#variables-for-specific-modes","title":"Variables for Specific Modes","text":""},{"location":"AdminManual/environment_variables/#server-and-default-mode","title":"SERVER and DEFAULT Mode","text":""},{"location":"AdminManual/environment_variables/#vix_host","title":"VIX_HOST","text":"<ul> <li>Description: Address to bind to in the <code>DEFAULT</code> or <code>SERVER</code> mode.</li> <li> <p>Default: <code>127.0.0.1</code> (binds to the local interface)</p> <p>Note</p> <p>The command-line argument <code>--host=HOST</code> takes precedence over the environment variable.</p> </li> </ul>"},{"location":"AdminManual/environment_variables/#vix_port","title":"VIX_PORT","text":"<ul> <li>Description: Port to bind to in the <code>DEFAULT</code> or <code>SERVER</code> mode.</li> <li> <p>Default: <code>8288</code></p> <p>Note</p> <p>The command-line argument <code>--port=PORT</code> takes precedence over the environment variable.</p> </li> </ul>"},{"location":"AdminManual/environment_variables/#vix_server_workers","title":"VIX_SERVER_WORKERS","text":"<ul> <li>Description: Number of server instances to spawn (using Uvicorn). Useful for production environments with a large number of users.</li> <li>Default: <code>1</code></li> </ul>"},{"location":"AdminManual/environment_variables/#vix_server_full_models","title":"VIX_SERVER_FULL_MODELS","text":"<ul> <li>Description: Flag that determines whether full models rather than dummy models should be stored in <code>SERVER</code> mode. Useful when both the Server and Workers are on the same machine, or when the <code>MODELS_DIR</code> is shared between the Server and Workers.</li> <li>Default: <code>0</code> (disabled)</li> <li>Set to: <code>1</code> to enable.</li> </ul>"},{"location":"AdminManual/environment_variables/#database_uri","title":"DATABASE_URI","text":"<ul> <li>Description: URI for the database used by Visionatrix. Required in <code>SERVER</code> mode.</li> <li>Default: <code>sqlite:///./tasks_history.db</code></li> <li>For SQLite: If the path is relative, it is relative to the current directory.</li> <li>Note: For PostgreSQL, the format is: <code>postgresql+psycopg://user:password@host:port/database</code></li> </ul>"},{"location":"AdminManual/environment_variables/#worker-mode","title":"WORKER Mode","text":"<p>When running in <code>WORKER</code> mode, the following variables are relevant:</p>"},{"location":"AdminManual/environment_variables/#vix_server","title":"VIX_SERVER","text":"<ul> <li>Description: The full URL of the Server to connect to when running in <code>WORKER</code> mode in the Worker to Server configuration.</li> <li> <p>Default: Empty string (must be set in <code>WORKER</code> mode if not using <code>DATABASE_URI</code>)</p> <p>Warning</p> <p>If <code>VIX_SERVER</code> is set, the Worker will communicate with the Server via the network; <code>DATABASE_URI</code> will be ignored.</p> <p>You are required to specify either <code>VIX_SERVER</code> or <code>DATABASE_URI</code> for the Worker, so it can fetch tasks to process.</p> </li> </ul>"},{"location":"AdminManual/environment_variables/#database_uri_1","title":"DATABASE_URI","text":"<ul> <li>Description: In <code>WORKER</code> mode, it is used only for the Worker to Database-FS configuration.</li> <li>Default: <code>sqlite:///./tasks_history.db</code></li> <li>Note: For Workers connecting directly to a PostgreSQL database, use the appropriate <code>DATABASE_URI</code>.</li> </ul>"},{"location":"AdminManual/environment_variables/#worker_auth","title":"WORKER_AUTH","text":"<ul> <li>Description: Authentication credentials for the Worker when connecting to the Server. Format: <code>USER_ID:PASSWORD</code></li> <li> <p>Default: <code>admin:admin</code></p> <p>Note</p> <p>This is only applicable for the Worker to Server configuration.</p> </li> </ul>"},{"location":"AdminManual/environment_variables/#worker_net_timeout","title":"WORKER_NET_TIMEOUT","text":"<ul> <li>Description: Network timeout in seconds for the Worker when communicating with the Server.</li> <li> <p>Default: <code>15.0</code></p> <p>Note</p> <p>This is only applicable for the Worker to Server configuration.</p> </li> </ul>"},{"location":"AdminManual/environment_variables/#other-variables","title":"Other Variables","text":""},{"location":"AdminManual/environment_variables/#flows_url","title":"FLOWS_URL","text":"<ul> <li>Description: URLs or file paths (separated by semicolons <code>;</code>) that point to locations of archive files containing lists and definitions of Visionatrix workflows. Specifies where Visionatrix fetches the available flows.</li> <li>Default: <code>https://visionatrix.github.io/VixFlowsDocs/</code></li> <li>More Information: Workflows Storage</li> </ul>"},{"location":"AdminManual/environment_variables/#models_catalog_url","title":"MODELS_CATALOG_URL","text":"<ul> <li>Description: URLs or file paths (separated by semicolons <code>;</code>) to fetch the models catalog for ComfyUI workflows. This catalog specifies available models.</li> <li>Default: <code>https://visionatrix.github.io/VixFlowsDocs/models_catalog.json</code></li> </ul>"},{"location":"AdminManual/environment_variables/#min_pause_interval","title":"MIN_PAUSE_INTERVAL","text":"<ul> <li>Description: Minimum interval in seconds (float) that the Worker waits between checking for new tasks when none are available. Helps reduce server load when idle.</li> <li>Default: <code>0.1</code></li> </ul>"},{"location":"AdminManual/environment_variables/#max_pause_interval","title":"MAX_PAUSE_INTERVAL","text":"<ul> <li>Description: Maximum interval in seconds (float) that the Worker waits between checking for new tasks when none are available. The pause interval increases gradually from <code>MIN_PAUSE_INTERVAL</code> to <code>MAX_PAUSE_INTERVAL</code> in 10 steps.</li> <li>Default: <code>1.0</code></li> </ul>"},{"location":"AdminManual/environment_variables/#gc_collect_interval","title":"GC_COLLECT_INTERVAL","text":"<ul> <li>Description: Interval in seconds (float) after which the GPU memory release and garbage collection procedure is called after task execution. Not recommended to change unless you know what you're doing.</li> <li>Default: <code>10.0</code></li> </ul>"},{"location":"AdminManual/environment_variables/#user_backends","title":"USER_BACKENDS","text":"<ul> <li>Description: List of user backends to enable. Each backend supports its own environment variables for configuration.</li> <li>Default: <code>vix_db</code></li> <li>Format: Semicolon-separated list of backends (e.g., <code>vix_db;nextcloud</code>)</li> <li>Example:   <pre><code>USER_BACKENDS=vix_db;nextcloud\n</code></pre>   This will enable the <code>nextcloud</code> user backend in addition to the default <code>vix_db</code>.</li> </ul>"},{"location":"AdminManual/environment_variables/#max_parallel_downloads","title":"MAX_PARALLEL_DOWNLOADS","text":"<ul> <li>Description: Maximum number of parallel downloads allowed during workflow installation.</li> <li>Default: <code>2</code></li> </ul>"},{"location":"AdminManual/environment_variables/#cors_origins","title":"CORS_ORIGINS","text":"<ul> <li>Description: A comma-separated list of origins that are allowed to make Cross-Origin Resource Sharing (CORS) requests to the server. This is necessary when the frontend and backend are hosted on different domains or ports. By specifying allowed origins, you enable frontend applications running on those origins to interact with the Visionatrix backend.</li> <li>Default: Empty string (CORS is disabled; only same-origin requests are allowed).</li> <li> <p>Example:</p> <pre><code>CORS_ORIGINS=\"http://localhost:3000,http://192.168.1.132:3000,http://192.168.1.132:8288\"\n</code></pre> <p>In this example, requests are permitted from:</p> <ul> <li><code>http://localhost:3000</code></li> <li><code>http://192.168.1.132:3000</code></li> <li><code>http://192.168.1.132:8288</code></li> </ul> <p>Note</p> <p>This setting is important when developing or deploying the frontend separately from the backend, especially during development when the frontend might be served by a development server on a different port.</p> </li> </ul>"},{"location":"AdminManual/environment_variables/#examples","title":"Examples","text":""},{"location":"AdminManual/environment_variables/#using-a-env-file_1","title":"Using a <code>.env</code> File","text":"<p>Create a file named <code>.env</code> in the root directory of Visionatrix with the following content:</p> <pre><code># Set the working mode to SERVER\nVIX_MODE=SERVER\n\n# Set the database URI to use PostgreSQL\nDATABASE_URI=postgresql+psycopg://vix_user:vix_password@localhost:5432/vix_db\n\n# Set the number of server workers\nVIX_SERVER_WORKERS=4\n\n# Enable full models on the server\nVIX_SERVER_FULL_MODELS=1\n\n# Specify the host and port to bind to\nVIX_HOST=0.0.0.0\nVIX_PORT=8000\n</code></pre>"},{"location":"AdminManual/environment_variables/#setting-variables-in-the-environment","title":"Setting Variables in the Environment","text":"<p>On Linux or macOS:</p> <pre><code>export VIX_MODE=WORKER\nexport VIX_SERVER=http://server_address:8000\nexport WORKER_AUTH=worker_user:worker_password\n</code></pre> <p>On Windows Command Prompt:</p> <pre><code>set VIX_MODE=WORKER\nset VIX_SERVER=http://server_address:8000\nset WORKER_AUTH=worker_user:worker_password\n</code></pre>"},{"location":"AdminManual/environment_variables/#starting-visionatrix-with-command-line-arguments","title":"Starting Visionatrix with Command-Line Arguments","text":"<pre><code>python3 -m visionatrix run --comfyui_dir=/path/to/comfyui --tasks_files_dir=/path/to/tasks_files --ui\n</code></pre> <p>In this example, the directories are specified via command-line arguments, which will override any environment variables or settings in the <code>.env</code> file.</p>"},{"location":"AdminManual/Installation/installation/","title":"Installation","text":"<p>In most cases, we recommend using automatic installation via an <code>easy-install</code> script.</p> <p>Download and execute <code>easy_install.py</code> script:</p> <p>Note</p> <p>It will clone this repository into the current folder and perform the installation.</p> <p>After installation you can always run <code>easy_install</code> from the \"scripts\" folder.</p> <p>With wget: <pre><code>wget -O easy_install.py https://raw.githubusercontent.com/Visionatrix/Visionatrix/main/scripts/easy_install.py &amp;&amp; python3 easy_install.py\n</code></pre></p> <p>or with curl: <pre><code>curl -o easy_install.py https://raw.githubusercontent.com/Visionatrix/Visionatrix/main/scripts/easy_install.py &amp;&amp; python3 easy_install.py\n</code></pre></p>"},{"location":"AdminManual/Installation/installation/#manual-installation","title":"Manual Installation","text":"<p>For those who want to install everything manually, here you will find step-by-step instructions on what the script does.</p>"},{"location":"AdminManual/Installation/installation/#virtual-environment-creation","title":"Virtual Environment creation","text":"<p>First clone the repository with <code>git</code>:</p> <pre><code>git clone https://github.com/Visionatrix/Visionatrix.git &amp;&amp; cd Visionatrix\n</code></pre> <p>Setup the virtual environment with <code>python</code>:</p> <pre><code>python -m venv venv\n</code></pre> <p>Activate Virtual Environment(Linux/macOS) with <code>source</code>:</p> <pre><code>source venv/bin/activate\n</code></pre> <p>Activate Virtual Environment(Windows) with <code>powershell</code>:</p> <pre><code>.\\venv\\Scripts\\Activate.ps1\n</code></pre>"},{"location":"AdminManual/Installation/installation/#pytorch-installation","title":"PyTorch installation","text":"<p>Note</p> <p>On macOS currently no action is needed.</p> <p>For AMD graphic cards on Linux install ROCM version of PyTorch using <code>pip</code>:</p> <pre><code>pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.1\n</code></pre> <p>For AMD graphics cards on Windows install PyTorch with DirectML support using <code>pip</code>:</p> <pre><code>pip install torch-directml\n</code></pre> <p>Python3.10 is the only currently supported version by torch-directml.</p> <p>For NVIDIA graphics cards on Linux install PyTorch with next <code>pip</code> command:</p> <pre><code>pip install torch torchvision torchaudio\n</code></pre> <p>For NVIDIA graphics cards on Windows install PyTorch using <code>pip</code> specifying PyTorch and CUDA version:</p> <pre><code>pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu121\n</code></pre>"},{"location":"AdminManual/Installation/installation/#install-visionatrix","title":"Install Visionatrix","text":"<p>Install Visionatrix from the previously cloned sources using <code>pip</code>:</p> <pre><code>pip install .\n</code></pre> <p>Run Visionatrix initialization command using <code>python</code>:</p> <pre><code>python -m visionatrix install\n</code></pre>"},{"location":"AdminManual/Installation/installation/#run-visionatrix","title":"Run Visionatrix","text":"<p>Execute from the activated virtual environment run command using <code>python</code>:</p> <pre><code>python -m visionatrix run --ui\n</code></pre>"},{"location":"AdminManual/Installation/installation/#update-process","title":"Update process","text":""},{"location":"AdminManual/Installation/installation/#recommended-way","title":"Recommended way","text":"<p>Note</p> <p>On Windows this method currently does not supported.</p> <p>With the <code>easy_install.py</code> script:</p> <pre><code>python3 scripts/easy_install.py\n</code></pre> <p>and select option Update (2)</p>"},{"location":"AdminManual/Installation/installation/#manual-update","title":"Manual Update","text":"<p>Note</p> <p>On Windows this method requires installed git and Visual Studio Compilers</p> <ol> <li> <p>Pull last changes from repository with <code>git</code>:</p> <pre><code>git pull\n</code></pre> </li> <li> <p>Execute update command from activated virtual environment with <code>python</code>:</p> <pre><code>python -m visionatrix update\n</code></pre> </li> </ol>"},{"location":"AdminManual/Installation/installation/#update-algorithm","title":"Update algorithm","text":"<p>Development versions are updated only to development versions, release versions only to release ones.</p> <p>Note</p> <p>If you are not a developer, you are better off using the release version, as they should be more stable.</p> <p>The update scheme in easy_install.py is quite simple; everything is done with ordinary Git commands.</p> <ul> <li> <p>If the current version is a dev release or the current branch is     <code>main</code> then:</p> <ol> <li>Check out the <code>main</code> branch.</li> <li>Pull the latest changes from the remote repository.</li> </ol> </li> <li> <p>If the current version is a tagged release version:</p> <ol> <li>Determine the latest tag for the current major version, and if     a newer version tag is found, check out the latest version tag     within the current major version.</li> <li>If no newer version is found within the current major version,     check for the next major version.</li> <li>If a newer major version tag is found, prompt the user to     update to this newer major version.</li> </ol> </li> <li> <p>After checking out the appropriate version, executes a <code>pip install</code>     command to update the Python packages.</p> </li> <li> <p>Finally, executes the <code>python3 -m visionatrix update</code> command to ensure     that any additional necessary updates are applied (ComfyUI, custom nodes, flows).</p> </li> </ul>"},{"location":"AdminManual/Installation/pgsql/","title":"How to Install PostgreSQL","text":"<p>This guide provides step-by-step instructions on how to install PostgreSQL on Linux, macOS, and Windows systems.</p> <p>This is recommended only for Visionatrix running in SERVER mode.</p>"},{"location":"AdminManual/Installation/pgsql/#installation-on-linux","title":"Installation on Linux","text":""},{"location":"AdminManual/Installation/pgsql/#installing-on-ubuntudebian","title":"Installing on Ubuntu/Debian","text":""},{"location":"AdminManual/Installation/pgsql/#step-1-update-package-lists","title":"Step 1: Update Package Lists","text":"<p>Open a terminal and update your package lists:</p> <pre><code>sudo apt update\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-2-install-postgresql","title":"Step 2: Install PostgreSQL","text":"<p>Install PostgreSQL along with the <code>postgresql-contrib</code> package, which provides additional utilities and features:</p> <pre><code>sudo DEBIAN_FRONTEND=noninteractive apt install -y postgresql postgresql-contrib\n</code></pre> <p>Note: This command will install the default version of PostgreSQL available in your distribution's repositories.</p>"},{"location":"AdminManual/Installation/pgsql/#step-3-start-postgresql","title":"Step 3: Start PostgreSQL","text":"<p>Start the PostgreSQL service:</p> <pre><code>sudo systemctl start postgresql\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#installing-on-centosrhel","title":"Installing on CentOS/RHEL","text":""},{"location":"AdminManual/Installation/pgsql/#step-1-add-repository","title":"Step 1: Add Repository","text":"<p>Enable the PostgreSQL repository for the desired version.</p> <p>Replace <code>13</code> with your preferred version (<code>12</code>, <code>13</code>, <code>14</code>, etc.):</p> <pre><code>sudo yum install -y https://download.postgresql.org/pub/repos/yum/13/redhat/rhel-$(rpm -E %{rhel})-x86_64/pgdg-redhat-repo-latest.noarch.rpm\n</code></pre> <p>Note: Where you see <code>postgresql13</code>, it can be <code>postgresql12</code> or <code>postgresql14</code> based on the version you want.</p>"},{"location":"AdminManual/Installation/pgsql/#step-2-disable-the-default-postgresql-module","title":"Step 2: Disable the Default PostgreSQL Module","text":"<p>For CentOS/RHEL 8 and newer:</p> <pre><code>sudo dnf -qy module disable postgresql\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-3-install-postgresql","title":"Step 3: Install PostgreSQL","text":"<p>Install PostgreSQL server:</p> <pre><code>sudo yum install -y postgresql13-server\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-4-initialize-and-enable","title":"Step 4: Initialize and Enable","text":"<p>Initialize the database and enable automatic start:</p> <pre><code>sudo /usr/pgsql-13/bin/postgresql-13-setup initdb\nsudo systemctl enable postgresql-13\nsudo systemctl start postgresql-13\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#installing-on-fedora","title":"Installing on Fedora","text":""},{"location":"AdminManual/Installation/pgsql/#step-1-install-postgresql","title":"Step 1: Install PostgreSQL","text":"<p>Install PostgreSQL server and contrib packages:</p> <pre><code>sudo dnf install postgresql-server postgresql-contrib\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-2-initialize-database","title":"Step 2: Initialize Database","text":"<p>Initialize the PostgreSQL database:</p> <pre><code>sudo postgresql-setup --initdb\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-3-start-postgresql_1","title":"Step 3: Start PostgreSQL","text":"<pre><code>sudo systemctl start postgresql\nsudo systemctl enable postgresql\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#installation-on-macos","title":"Installation on macOS","text":""},{"location":"AdminManual/Installation/pgsql/#using-homebrew","title":"Using Homebrew","text":""},{"location":"AdminManual/Installation/pgsql/#step-1-install-homebrew","title":"Step 1: Install Homebrew","text":"<p>If you don't have Homebrew installed, run:</p> <pre><code>/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-2-update-homebrew","title":"Step 2: Update Homebrew","text":"<pre><code>brew update\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-3-install-postgresql_1","title":"Step 3: Install PostgreSQL","text":"<pre><code>brew install postgresql\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-4-start-postgresql","title":"Step 4: Start PostgreSQL","text":"<p>To start PostgreSQL now and restart at login:</p> <pre><code>brew services start postgresql\n</code></pre> <p>Or, to run it manually:</p> <pre><code>pg_ctl -D /usr/local/var/postgres start\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#using-postgresql-installer","title":"Using PostgreSQL Installer","text":""},{"location":"AdminManual/Installation/pgsql/#step-1-download-the-installer","title":"Step 1: Download the Installer","text":"<p>Download the PostgreSQL installer for macOS from the official PostgreSQL website.</p>"},{"location":"AdminManual/Installation/pgsql/#step-2-run-the-installer","title":"Step 2: Run the Installer","text":"<ul> <li>Open the downloaded <code>.dmg</code> file.</li> <li>Run the installer and follow the on-screen instructions.</li> <li>Set a password for the <code>postgres</code> user when prompted.</li> </ul>"},{"location":"AdminManual/Installation/pgsql/#installation-on-windows","title":"Installation on Windows","text":""},{"location":"AdminManual/Installation/pgsql/#postgresql-installer","title":"PostgreSQL Installer","text":""},{"location":"AdminManual/Installation/pgsql/#step-1-download-the-installer_1","title":"Step 1: Download the Installer","text":"<p>Download the PostgreSQL installer for Windows from the official PostgreSQL website.</p>"},{"location":"AdminManual/Installation/pgsql/#step-2-run-the-installer_1","title":"Step 2: Run the Installer","text":"<ul> <li>Double-click the downloaded <code>.exe</code> file.</li> <li>Follow the installation wizard steps:<ul> <li>Set a password for the PostgreSQL superuser (<code>postgres</code>).</li> <li>Choose the port number (default is 5432).</li> <li>Wait for the installation to complete.</li> </ul> </li> </ul>"},{"location":"AdminManual/Installation/pgsql/#post-installation-setup","title":"Post-Installation Setup","text":""},{"location":"AdminManual/Installation/pgsql/#initializing-the-database","title":"Initializing the Database","text":"<p>In most cases, the database is initialized during installation. If not, follow the steps below.</p>"},{"location":"AdminManual/Installation/pgsql/#on-linux","title":"On Linux","text":"<p>For versions installed via package managers:</p> <pre><code>sudo su - postgres\n</code></pre> <p>Then initialize the database(not always required):</p> <pre><code>initdb -D /var/lib/pgsql/data\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#starting-the-postgresql","title":"Starting the PostgreSQL","text":"<p>Ensure PostgreSQL is running and set to start on boot.</p>"},{"location":"AdminManual/Installation/pgsql/#on-ubuntudebian","title":"On Ubuntu/Debian","text":"<pre><code>sudo systemctl start postgresql\nsudo systemctl enable postgresql\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#on-centosrhel","title":"On CentOS/RHEL","text":"<pre><code>sudo systemctl start postgresql-13\nsudo systemctl enable postgresql-13\n</code></pre> <p>Note: Replace <code>13</code> with your PostgreSQL version number.</p>"},{"location":"AdminManual/Installation/pgsql/#on-fedora","title":"On Fedora","text":"<pre><code>sudo systemctl start postgresql\nsudo systemctl enable postgresql\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#on-macos-manual-start","title":"On macOS (Manual Start)","text":"<pre><code>pg_ctl -D /usr/local/var/postgres start\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#creating-a-user-and-database","title":"Creating a User and Database","text":"<p>We will create a database named <code>vix_db</code> and a user <code>vix_user</code> with password <code>vix_password</code>, as required by Visionatrix.</p>"},{"location":"AdminManual/Installation/pgsql/#option-1-via-pgsql-shell","title":"Option 1: Via PgSQL Shell","text":""},{"location":"AdminManual/Installation/pgsql/#step-1-switch-to-postgres","title":"Step 1: Switch to <code>postgres</code>","text":"<pre><code>sudo -u postgres psql\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-2-create-user","title":"Step 2: Create User","text":"<pre><code>CREATE USER vix_user WITH PASSWORD 'vix_password';\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-3-create-database","title":"Step 3: Create Database","text":"<pre><code>CREATE DATABASE vix_db OWNER vix_user;\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-4-grant-privileges","title":"Step 4: Grant Privileges","text":"<pre><code>GRANT ALL PRIVILEGES ON DATABASE vix_db TO vix_user;\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#step-5-exit-shell","title":"Step 5: Exit Shell","text":"<pre><code>\\q\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#option-2-direct-commands","title":"Option 2: Direct Commands","text":"<p>You can execute all commands directly from the terminal:</p> <pre><code>sudo -u postgres psql -c \"CREATE USER vix_user WITH PASSWORD 'vix_password';\"\nsudo -u postgres psql -c \"CREATE DATABASE vix_db OWNER vix_user;\"\nsudo -u postgres psql -c \"GRANT ALL PRIVILEGES ON DATABASE vix_db TO vix_user;\"\n</code></pre>"},{"location":"AdminManual/Installation/pgsql/#configuring-visionatrix","title":"Configuring Visionatrix","text":"<p>After installing and configuring PostgreSQL, you need to set the <code>DATABASE_URI</code> environment variable for Visionatrix to connect to the PostgreSQL database.</p> <p>Set the <code>DATABASE_URI</code> as follows:</p> <pre><code>DATABASE_URI=\"postgresql+psycopg://vix_user:vix_password@localhost:5432/vix_db\"\n</code></pre> <p>This tells Visionatrix to connect to the PostgreSQL database <code>vix_db</code> on <code>localhost</code> using the user <code>vix_user</code> and password <code>vix_password</code> on port <code>5432</code>.</p> <p>Make sure to export this variable or set it in your Visionatrix configuration file as per the installation instructions.</p> <p>Good luck!</p>"},{"location":"AdminManual/Installation/proxy_gemini/","title":"HTTP Proxy for Google Gemini API Access","text":"<p>This guide will help you set up an HTTP/HTTPS proxy to use the Google Gemini API.</p> <p>This is useful if you're in a region where free direct access to the Gemini API is restricted.</p> <p>Warning</p> <p>For most countries in the world you don't need this guide!</p> <p>If you use Gemini Pro model - you don't need it either, it doesn't have free access, and paid access works from everywhere and without proxy.</p> <p>Note</p> <p>The information on this page is provided for educational purposes, so that you can check what Gemini Flash is capable of before connecting the payment method to your Google account.</p>"},{"location":"AdminManual/Installation/proxy_gemini/#prerequisites","title":"Prerequisites","text":"<ul> <li>A Virtual Private Server (VPS) or access to a machine with a public IP address.</li> <li>Basic knowledge of server administration and command-line operations.</li> <li>A valid Google API Key.</li> </ul>"},{"location":"AdminManual/Installation/proxy_gemini/#why-use-a-proxy","title":"Why Use a Proxy?","text":"<p>In certain regions, direct access to the Google Gemini API may be limited or unavailable. By routing your requests through a proxy server located in a supported country, you can bypass these restrictions and use the API seamlessly.</p>"},{"location":"AdminManual/Installation/proxy_gemini/#step-by-step-guide","title":"Step-by-Step Guide","text":""},{"location":"AdminManual/Installation/proxy_gemini/#1-obtain-vps-or-access-to-machine-with-public-ip","title":"1. Obtain VPS or access to machine with Public IP","text":"<p>You'll need to set up a proxy on a server located in a country where the Google Gemini API is accessible, such as the United States or India.</p>"},{"location":"AdminManual/Installation/proxy_gemini/#recommended-vps-providers","title":"Recommended VPS Providers","text":"<ul> <li>DigitalOcean: Offers affordable VPS options starting at <code>$4</code> per month.</li> </ul>"},{"location":"AdminManual/Installation/proxy_gemini/#2-set-up-a-proxy-server-using-squid","title":"2. Set Up a Proxy Server Using Squid","text":"<p>We recommend using Squid, a high-performance proxy caching server for web clients.</p>"},{"location":"AdminManual/Installation/proxy_gemini/#install-squid-on-your-vps","title":"Install Squid on Your VPS","text":"<p>Follow this comprehensive guide to install and configure Squid:</p> <ul> <li>DigitalOcean Squid Installation Guide: How To Set Up Squid Proxy on Ubuntu 20.04</li> </ul>"},{"location":"AdminManual/Installation/proxy_gemini/#3-configure-visionatrix-to-use-the-proxy","title":"3. Configure Visionatrix to Use the Proxy","text":"<p>After setting up your proxy server, update Visionatrix settings to route API requests through it.</p>"},{"location":"AdminManual/Installation/proxy_gemini/#steps-to-configure-visionatrix","title":"Steps to Configure Visionatrix","text":"<ol> <li> <p>Navigate to the Settings page.</p> </li> <li> <p>Input your valid Google API key.</p> </li> <li> <p>Enter your proxy server's connection string.</p> <p>Format Examples:</p> <ul> <li>Without authentication:</li> </ul> <pre><code>http://proxy_host:proxy_port\n</code></pre> <ul> <li>With authentication:</li> </ul> <pre><code>http://username:password@proxy_host:proxy_port\n</code></pre> <p>Example:</p> <ul> <li>If your proxy's IP is <code>203.0.113.1</code> and port is <code>3128</code>:</li> </ul> <pre><code>http://203.0.113.1:3128\n</code></pre> </li> <li> <p>Save the Settings</p> </li> </ol>"},{"location":"AdminManual/Installation/proxy_gemini/#4-alternative-access-the-gemini-api-without-a-proxy","title":"4. Alternative: Access the Gemini API Without a Proxy","text":"<p>If you have a payment card connected, you can access the Gemini API directly from almost any country in the world.</p> <ol> <li> <p>Ensure Billing Is Set Up:</p> <ul> <li>Log in to your Google Cloud Platform account.</li> <li>Verify that your billing information and credit card are properly connected.</li> </ul> </li> <li> <p>Configure Visionatrix:</p> <ul> <li>Enter your Google API Key in the designated field.</li> <li>Leave the \"Google Proxy\" field empty.</li> </ul> </li> <li> <p>You can select the Gemini Model to use in Visionatrix settings:</p> <ul> <li>Gemini Flash(default): An affordable option suitable for most users.</li> <li>Gemini Pro: Offers superior results but is not available for free.</li> </ul> </li> </ol>"},{"location":"AdminManual/WorkingModes/worker_to_database/","title":"Setup: Worker to Database-FS Mode","text":"<p>This is the simplest production setup, when everything is up and running on one server.</p> <p>Note</p> <p>We also use this setup for benchmarks.</p> <p>This guide is for Ubuntu. Adjust it to your needs for different Linux distributions.</p> <ol> <li> <p>Log in to the server: <code>ssh ...</code></p> <p>Note</p> <p>if necessary, add port forwarding: -L 127.0.0.1:8288:127.0.0.1:8288</p> </li> <li> <p>If you are logged in as the <code>root</code> user on a clean system, install <code>sudo</code>:</p> <pre><code>apt update &amp;&amp; apt install -y sudo\n</code></pre> </li> <li> <p>Install Python, Git, and essential build tools:</p> <pre><code>sudo apt update &amp;&amp; sudo apt install -y wget curl python3-venv python3-pip build-essential git\n</code></pre> <p>Note</p> <p>On some systems you need additionally to install <code>cv2</code> dependencies:</p> <pre><code>sudo apt install -y ffmpeg libsm6 libxext6\n</code></pre> </li> <li> <p>Install and start PostgreSQL:</p> <pre><code>sudo systemctl start postgresql\nsudo systemctl enable postgresql\nsudo systemctl status postgresql\n</code></pre> <p> For benchmark automation script <p><pre><code>sudo DEBIAN_FRONTEND=noninteractive apt install -y postgresql postgresql-contrib &amp;&amp; pg_ctlcluster 14 main start &amp;&amp; \\\n\\\nsudo -u postgres psql -c \"CREATE USER vix_user WITH PASSWORD 'vix_password';\" &amp;&amp; \\\nsudo -u postgres psql -c \"CREATE DATABASE vix_db OWNER vix_user;\" &amp;&amp; \\\nsudo -u postgres psql -c \"GRANT ALL PRIVILEGES ON DATABASE vix_db TO vix_user;\"\n</code></pre> </p> <li> <p>Create a Visionatrix DB user:</p> <pre><code>sudo -u postgres psql -c \"CREATE USER vix_user WITH PASSWORD 'vix_password';\"\nsudo -u postgres psql -c \"CREATE DATABASE vix_db OWNER vix_user;\"\nsudo -u postgres psql -c \"GRANT ALL PRIVILEGES ON DATABASE vix_db TO vix_user;\"\n</code></pre> <p>Warning</p> <p>If you encounter the following error during Visionatrix startup:</p> <p><code>password authentication failed for user \"vix_user\"</code></p> <p>   This means you need to enable password authentication for the <code>vix_user</code>. <p>Edit <code>pg_hba.conf</code> file (typically located at <code>/etc/postgresql/XX/main/pg_hba.conf</code>) by adding following:</p> <pre><code>host    all             vix_user        127.0.0.1/32            md5\n</code></pre> <p>Then, restart PostgreSQL:</p> <pre><code>sudo systemctl restart postgresql\n</code></pre> <p>or</p> <pre><code>sudo service postgresql restart\n</code></pre> <li> <p>Install Visionatrix:</p> <pre><code>wget -O easy_install.py https://raw.githubusercontent.com/Visionatrix/Visionatrix/main/scripts/easy_install.py &amp;&amp; \\\npython3 easy_install.py &amp;&amp; \\\ncd Visionatrix &amp;&amp; source venv/bin/activate &amp;&amp; \\\npip install \".[pgsql]\" &amp;&amp; \\\n\\\nUSER_PASSWORD=$(openssl rand -base64 32 | tr -dc 'A-Za-z0-9' | head -c 16) &amp;&amp; \\\nDATABASE_URI=\"postgresql+psycopg://vix_user:vix_password@localhost:5432/vix_db\" \\\npython3 -m visionatrix create-user --name admin --password \"$USER_PASSWORD\" &amp;&amp; \\\necho \"User 'admin' created with password: $USER_PASSWORD\"\n</code></pre> <p> For benchmark automation script (CUDA, Dev version) <p><pre><code>wget -O easy_install.py https://raw.githubusercontent.com/Visionatrix/Visionatrix/main/scripts/easy_install.py &amp;&amp; \\\nCOMPUTE_DEVICE=NVIDIA DEV_VERSION=1 BUILD_RELEASE=1 python3 easy_install.py &amp;&amp; \\\ncd Visionatrix &amp;&amp; source venv/bin/activate &amp;&amp; \\\npip install \".[pgsql]\" &amp;&amp; \\\npython3 scripts/easy_install.py &amp;&amp; \\\n\\\nUSER_PASSWORD=$(openssl rand -base64 32 | tr -dc 'A-Za-z0-9' | head -c 16) &amp;&amp; \\\nDATABASE_URI=\"postgresql+psycopg://vix_user:vix_password@localhost:5432/vix_db\" \\\npython3 -m visionatrix create-user --name admin --password \"$USER_PASSWORD\" &amp;&amp; \\\necho \"User 'admin' created with password: $USER_PASSWORD\"\n</code></pre> </p> <li> <p>Start the Visionatrix Server(from activated venv):</p> <pre><code>DATABASE_URI=\"postgresql+psycopg://vix_user:vix_password@localhost:5432/vix_db\" \\\nVIX_SERVER_FULL_MODELS=1 python3 -m visionatrix run --ui --mode=SERVER &gt; server.log 2&gt;&amp;1 &amp; echo \"Server PID: $!\"\n</code></pre> </li> <li> <p>Start the Visionatrix Worker(from activated venv):</p> <pre><code>DATABASE_URI=\"postgresql+psycopg://vix_user:vix_password@localhost:5432/vix_db\" \\\npython3 -m visionatrix run --mode=WORKER &gt; worker.log 2&gt;&amp;1 &amp; echo \"Worker PID: $!\"\n</code></pre> </li>"},{"location":"AdminManual/WorkingModes/working_modes/","title":"Working modes","text":""},{"location":"AdminManual/WorkingModes/working_modes/#default","title":"DEFAULT","text":"<p>Visionatrix(Vix) consists of:</p> <ol> <li>A server component, namely, the backend <code>(in short - Server)</code></li> <li>A component responsible for processing tasks <code>(in short - Worker)</code></li> <li>TaskQueue - a database (SQLite (default), PgSQL)</li> <li>A simple and understandable User Interface</li> </ol> <p>By default, Vix launches with all components integrated (Server + Worker + UI) for quick and easy use on a single computer.</p> <p>This is DEFAULT mode, in which everything is executed within a single process.</p> <p>Easy installation, no need to configure, just launch and use.</p> <p>Note</p> <p>There is no support for multiple users or authentication in this case, as this mode uses SQLite as a database, which is limiting. But for home use in most cases this is not necessary.</p>"},{"location":"AdminManual/WorkingModes/working_modes/#server","title":"SERVER","text":"<p>In most scenarios, including home use, you likely have more than one device capable of handling AI tasks. In such cases, it is allowed and recommended to run the server part and the AI processing part of the task separately.</p> <p>Warning</p> <p>We recommend using PgSQL database in this mode, as SQLite does not support parallel data writing..</p> <p>Steps to run <code>Vix</code> in a Server mode:</p> <ol> <li> <p>Install both <code>psycopg</code> and <code>greenlet</code> python libraries:</p> <p><code>pip install psycopg greenlet</code></p> </li> <li> <p>Set <code>VIX_MODE</code> environment variable to <code>SERVER</code></p> </li> <li> <p>Setup PostgreSQL database and set <code>DATABASE_URI</code> environment variable to point on it.</p> <p>Note</p> <p>PgSQL example: <code>DATABASE_URI=\"postgresql+psycopg://vix_user:vix_password@localhost:5432/vix_db\"</code></p> </li> <li> <p>Use <code>python3 -m visionatrix create-user</code> command to create a user in the database.</p> </li> <li> <p>Connect at least one Worker to handle task processing.</p> </li> </ol> <p>We will provide a docker-compose file soon, with full server setup to deploy it in one click.</p>"},{"location":"AdminManual/WorkingModes/working_modes/#worker","title":"WORKER","text":"<p>Each worker can have a different set of tasks (Flows) installed, which is useful to avoid installing a task on a worker instance that cannot handle it. A worker will only request the tasks installed for it.</p> <p>There is two worker modes, both will be described, we ourselves most use *Vix in the <code>Worker to Server</code> mode.</p>"},{"location":"AdminManual/WorkingModes/working_modes/#worker-to-database-fs","title":"Worker to Database-FS","text":"<p>Note</p> <p>Requirements:</p> <ol> <li>The database used by the Server should be accessible for the worker.</li> <li>There should be the ability to map the Server's <code>vix_tasks_files</code> folder to the worker.</li> </ol> <p>Set the environment variable <code>VIX_MODE</code> to WORKER and leave <code>VIX_SERVER</code> with an empty value.</p> <p>In this scenario, the worker must be configured with the correct database path using the <code>DATABASE_URI</code> environment variable.</p> <p>The format can be viewed here: SqlAlchemy Database URLs</p> <p>By using the <code>TASKS_FILES_DIR</code> environment variable or the <code>--tasks_files_dir</code> argument, you can change the location of the <code>vix_tasks_files</code> folder.</p> <p>The worker must have access to the Server's <code>vix_tasks_files</code> folder.</p> <p>With this scaling method, workers independently retrieve tasks from the database and directly write the execution results to the servers TASKS_FILES_DIR.</p> <p>In this setup, you can imagine workers as Server threads operating remotely.</p> <p>See installation guide for this mode: Worker To Database-FS</p>"},{"location":"AdminManual/WorkingModes/working_modes/#worker-to-server","title":"Worker to Server","text":"<p>This method implies that the workers do not have direct access to the database or the server file system.</p> <p>All communication occurs through the network, with workers accessing the server backend directly.</p> <p>Set the environment variable <code>VIX_MODE</code> to WORKER and set <code>VIX_SERVER</code> with the full address of the Server(including port number).</p> <p>Note</p> <p><code>VIX_HOST</code>, <code>VIX_PORT</code>, <code>DATABASE_URI</code> will be ignored, as the worker in this mode does not need it.</p> <p>In this use case, the vix_tasks_files directory will contain only temporary files; after uploading results to the Server, the results from the worker instance will be cleared.</p> <p>For authentication on the server worker will use <code>WORKER_AUTH</code> environment variable, which must contain \"USER_ID:PASSWORD\".</p> <p>Note</p> <p>Workers with an administrator account can process all tasks of all users, workers assigned to a user account can only process tasks created by that user.</p>"},{"location":"Flows/","title":"Available Flows","text":"<p>Note</p> <p>Results of Flows time execution is now located at Hardware Test Results</p> <ul> <li>Colorful XL</li> <li>Juggernaut Lite</li> <li>Juggernaut XL</li> <li>Mobius XL</li> <li>SDXL Lighting</li> <li>Hunyuan DiT</li> <li>Stable Cascade</li> <li>Playground 2.5 Prometheus</li> <li>Playground 2.5 Aesthetic</li> <li>Comicu Portrait</li> <li>Vintage Portrait</li> <li>Memoji Portrait</li> <li>Sketch Portrait</li> <li>Photomaker 1</li> <li>Photomaker 2</li> <li>Photo Stickers</li> <li>Photo Stickers 2</li> <li>Mad Scientist</li> <li>Supir Upscaler</li> <li>Human Face Detailer</li> <li>Flux 1</li> <li>Inpaint</li> <li>AllYourLife</li> </ul>"},{"location":"Flows/AllYourLife/","title":"All Your Life","text":"<p>Original Workflow by Datou.</p> <p>Workflow is quite demanding, 8 images in a batch generates throw 2 nodes using 8 steps in each(128 steps total) - so it if not blazing fast.</p> <p>Photos are best given when person are relatively young or middle-aged.</p> <p>Don't even try to give photos of an old person unless you want to get a video from a horror movie.</p>"},{"location":"Flows/AllYourLife/#examples","title":"Examples","text":""},{"location":"Flows/Colorful_XL/","title":"Colorful XL","text":"<p>A fairly simple flow at the moment, simply using the latest Colorful XL model without any post-processing.</p> <p>Warning</p> <p>Not Safe for Work (NSFW) version.</p> <p>Supports various aspect ratios.</p> <p>Supports fast generation using the Align Steps technique</p>"},{"location":"Flows/Colorful_XL/#examples","title":"Examples","text":"<pre><code>portrait, half-robot woman, in the dark, contrasting light, realistic, masterpiece\n</code></pre> <pre><code>half-cat woman, in the forest, vivid lights, realistic, masterpiece\n</code></pre> <ul> <li>Fast Run: true, Vibrancy: 3</li> </ul> <pre><code>portrait, young man, angel, sky, sun, high contrast\n</code></pre> <ul> <li>Fast Run: true, Vibrancy: 2, Steps number to generate: 60</li> </ul>"},{"location":"Flows/ComicuPortrait/","title":"ComicU Anime Portrait","text":"<p>Create an anime(sketch by default) image from a photo of a person.</p> <p>Prompt is optional, something like emotions can be used there: smile, sad, serious, etc.</p> <p>If you ticked the \"Disable Simple style\" you can try to add something like line-sketch to the prompt.</p> <p>Part of the flow runs on the CPU, part on the GPU, the flow is quite fast and convenient for everyday use.</p>"},{"location":"Flows/ComicuPortrait/#examples","title":"Examples","text":"<p>As input files, the photos of <code>Bruce Lee</code> and <code>Shakira</code> were taken from the Internet and used.</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"Flows/Flux_1/","title":"Flux 1","text":"<p>FLUX.1 is a 12 billion parameter rectified flow transformer capable of generating images from text descriptions. For more information, please read blog post</p> <p>The model is extremely demanding on hardware.</p> <p>Even on 24 Gigabytes, the speed of the model in the full version leaves much to be desired, since this basic flow does not fit completely into the video card cache.</p> <p>Lightning versions are quite good and generate quite good pictures in 4 steps.</p> <p>Totally with these models there are 4 different flows:</p> <ul> <li>Flux</li> <li>Flux (Small)</li> <li>Flux Lighting</li> <li>Flux Lighting (Small)</li> </ul> <p>Supports various aspect ratios.</p> <p>Supports different number of steps for non-Lighting versions.</p>"},{"location":"Flows/Flux_1/#flux-small-example","title":"Flux Small Example","text":"<pre><code>photo-realistic portrait of a cute kitten in cyberpunk style holding sign \"Visionatrix\" in ultra quality with high details\n</code></pre>"},{"location":"Flows/Flux_1/#flux-lighting-example","title":"Flux Lighting Example","text":"<pre><code>A cool man is driving a luxury car through a night city. The scene captures the vibrant nightlife with glowing neon signs, tall skyscrapers, and bustling streets. The dad is stylishly dressed, exuding confidence and charisma. The luxury car, sleek and modern, reflects the city lights, enhancing the atmosphere of urban sophistication and adventure.\n</code></pre>"},{"location":"Flows/Flux_1/#flux-example-50-steps","title":"Flux Example (50 steps)","text":"<pre><code>Portrait of beautiful woman in a swimsuit is lounging under a palm tree on a tropical beach. The scene is photorealistic, capturing the serene and picturesque setting with clear blue skies, gentle waves, and white sandy shores. The palm tree provides shade, and the overall atmosphere is one of leisure and tropical paradise.\n</code></pre>"},{"location":"Flows/HumanFaceDetailer/","title":"Human Face Detailer","text":"<p>Initially this was part of Playground 2.5 Aesthetics Flow until Visionatrix 1.0 version.</p> <p>It was decided to move it to a separate flow, so that it would be convenient to send the result of any flow here.</p> <p>This flow works by default at the moment on the CPU.</p> <p>The maximum number of faces for redrawing on a portrait is limited to 3.</p> <p>If no faces are found in the input image, nothing will be redrawn.</p>"},{"location":"Flows/HumanFaceDetailer/#examples","title":"Examples","text":""},{"location":"Flows/HunyuanDiT/","title":"HunyuanDiT","text":"<p>Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding.</p> <p>A solid model that supports natively very high Vibrancy.</p>"},{"location":"Flows/HunyuanDiT/#examples","title":"Examples","text":"<pre><code>portrait of a majestic insect\n</code></pre> <ul> <li>Vibrancy: 7, Steps: 60</li> </ul> <pre><code>close portrait of happy girl on the great wall\n</code></pre> <ul> <li>Vibrancy: 7, Steps: 60</li> </ul> <pre><code>portrait of a black pug on the yellow grass\n</code></pre> <ul> <li>Vibrancy: 6, Steps: 30</li> </ul>"},{"location":"Flows/Inpaint/","title":"Inpaint","text":"<p>Currently only a few inpaint flows are available:</p> <ul> <li>Flux Redraw</li> <li>Flux Redraw (Small)</li> <li>Flux Redraw Lighting (Small)</li> <li>ColorfulXL</li> </ul> <p>Inpainting is hard, you always need to try to select the correct Replacing factor parameter, and it strongly depends on the image and the flow.</p> <p>As examples, we will use real photos, it is harder to inpaint them, since they have a high resolution, and current models draw in 1024x1024 resolution.</p> <p>It is easier to \"repaint\" photos generated with AI, as they have usually low resolutions.</p>"},{"location":"Flows/Inpaint/#examples","title":"Examples","text":"<p>Original:</p> <p></p> <p>Results of painting long and lush luxurious hair:</p> <p> </p> <p>Results of painting on the left of the man:</p> <p> </p> <p>Results of painting Mooon the right of the man:</p> <p></p> <p>Original with baby photo:</p> <p></p> <p>Results of redrawing the upper part of the image:</p> <p> </p>"},{"location":"Flows/Juggernaut_Lite/","title":"Juggernaut Lite","text":"<p>This flow is most suitable for generating people quickly and realistically.</p> <p>Although it sometimes has problems with eyes or hands, in most cases the quality is quite acceptable.</p> <p>Supports various aspect ratios.</p>"},{"location":"Flows/Juggernaut_Lite/#examples","title":"Examples","text":"<pre><code>portrait of hero wearing cuirass sitting on the chair, high details, photo realistic\n</code></pre> <pre><code>portrait of elf man in obsidian armor looking at viewer from the dark, contrast, high details\n</code></pre> <pre><code>portrait rage tiger\n</code></pre>"},{"location":"Flows/Juggernaut_XL/","title":"Juggernaut XL","text":"<p>A fairly simple flow at the moment, simply using the latest Juggernaut X model without any post-processing.</p> <p>Note: Not Safe for Work (NSFW) version.</p> <p>Prompting information can be found here: Juggernaut-X prompting</p> <p>Supports various aspect ratios.</p> <p>Supports fast generation using the Align Steps technique</p>"},{"location":"Flows/Juggernaut_XL/#examples","title":"Examples","text":"<pre><code>close portrait of hero wearing cuirass sitting on the chair, high details\n</code></pre> <pre><code>portrait of elf man in obsidian armor looking at viewer from the dark, contrast, high details\n</code></pre> <pre><code>portrait rage tiger, high resolution\n</code></pre>"},{"location":"Flows/MadScientist/","title":"Mad Scientist","text":"<p>This feature requires vision capabilities.</p> <p>You must either have the Ollama server running with the llava:7b-v1.6-vicuna-q8_0 model, or provide a <code>Gemini API key</code> in the settings.</p> <p>There are only two required arguments:</p> <ol> <li>Source file with a person's face.</li> <li>The file from which style will be created and applied to the source file.</li> </ol> <p>The results of this flow are amazing.</p>"},{"location":"Flows/MadScientist/#hardware-requirements","title":"Hardware requirements","text":"<p>Depends on whether the Ollama server is running locally or remotely.</p> <p>It can run on Macbook 32GB (including Ollama running locally on the same device)</p> <p>Since the Ollama model used here requires 7GB models and uses SDXL models from the workflow, it will likely require a 16GB memory card to run it on the GPU.</p> <p>But you can always run Ollama on a CPU or other device and after that a 10GB graphics card will be enough.</p>"},{"location":"Flows/MadScientist/#examples","title":"Examples","text":""},{"location":"Flows/MemojiPortrait/","title":"Memoji Portrait","text":"<p>Create cute Memoji from a photo of a person.</p> <p>Prompt is required, simplest examples is: <code>girl, portrait, close up</code></p> <pre><code>To make it look more like Memoji you can add **sico style** words:\n`**sico style**, girl, portrait, close up`\n</code></pre> <p>Person's face pose is optional.</p> <p>Part of the flow runs on the CPU, part on the GPU, the flow is quite fast and convenient for everyday use.</p>"},{"location":"Flows/MemojiPortrait/#examples","title":"Examples","text":"<p>As input files, the photos of <code>Bruce Lee</code> and <code>Einstein</code> were taken from the Internet and used.</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"Flows/Mobius_XL/","title":"Mobius XL","text":"<p>A fairly simple flow at the moment, simply using the latest Mobius model without any post-processing.</p> <p>This is a very unusual model, although it is part of the SDXL family of models - its results in some areas are simply amazing.</p> <p>It has better text drawing capabilities than other SDXL models.</p> <p>Since the author of this model is constantly improving it, we will update it with new versions when they are published.</p> <p>Here is a link to civitai to learn more about the model.</p> <p>Link to the author of the model on Twitter</p> <p>Supports fast generation using the Align Steps technique</p>"},{"location":"Flows/Mobius_XL/#examples","title":"Examples","text":"<pre><code>emotional owl looks at the viewer in surprise, masterpiece, cinematic, best quality\n</code></pre> <pre><code>very angry emotional pug, future, best quality, masterpiece, cinematic, (\"VIX\" text logo)\n</code></pre> <pre><code>portrait of male paratrooper, explosions background, masterpiece, cinematic, best quality\n</code></pre>"},{"location":"Flows/PhotoStickers/","title":"Photo Stickers","text":"<p>Turns a photo into 4 anime stickers with different emotions.</p> <p>Part of the flow runs on the CPU, part on the GPU, the flow is quite fast and convenient for everyday use.</p>"},{"location":"Flows/PhotoStickers/#examples","title":"Examples","text":"<p>As input file, the photo of <code>Bruce Lee</code> was taken from the Internet and used.</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"Flows/PhotoStickers2/","title":"Photo Stickers 2","text":"<p>This feature requires vision capabilities.</p> <p>You must either have the Ollama server running with the llava:7b-v1.6-vicuna-q8_0 model, or provide a <code>Gemini API key</code> in the settings.</p> <p>Turns a photo into 4 stickers using different prompts.</p> <p>Part of the flow runs on the CPU, part on the GPU, the flow is quite fast and convenient for everyday use.</p> <p>Original flow/idea examples: StickerYou - 1 photo for stickers</p>"},{"location":"Flows/PhotoStickers2/#examples","title":"Examples","text":"<p>As input file, the photo of <code>Bruce Lee</code> was taken from the Internet and used with default prompts.</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"Flows/Photomaker_1/","title":"Photomaker","text":"<p>Creates fairly good and realistic images of a person in different styles based on one photo. The person's face in the incoming image should preferably occupy most of the screen.</p> <p>Advanced parameter Accuracy currently applies only to one result image.</p> <p>Note</p> <p>Recommended words to be present in the prompt: woman/girl/man/boy</p>"},{"location":"Flows/Photomaker_1/#examples","title":"Examples","text":"<p>The image of <code>Bruce Lee</code> was taken from the Internet and used as a basis for first two prompts,     for the third prompt <code>Erin Starlight</code> photo was used.</p> <p> </p> <pre><code>portrait of man photomaker in green suite with dragons\n</code></pre> <ul> <li>Style: Cinematic</li> </ul> <p> </p> <pre><code>portrait of man photomaker looking at viewer from the dark, fire and flames\n</code></pre> <ul> <li>Style: Neonpunk</li> </ul> <p> </p> <pre><code>portrait of woman photomaker wearing suite in the forest looking at viewer\n</code></pre> <ul> <li>Style: Comic book</li> </ul>"},{"location":"Flows/Photomaker_2/","title":"Photomaker 2","text":"<p>This flow is based on the second version of Tencent's model. Its results are significantly better, but there are a few caveats:</p> <ol> <li> <p>The flow is highly sensitive to the input photos and their angles.</p> <p>(ideally, you should provide 3 photos: a profile, slightly from the left, and slightly from the right)</p> </li> <li> <p>At least 2 photos are required, but sometimes 3-4 are needed to achieve acceptable results.</p> </li> </ol> <p>Note</p> <p>We have added face cropping and background removal to this flow, si no need to select an input where the face occupies a large portion of the image.</p> <p>This flow produces 3 results instead of 2, so it takes a bit longer to process.</p> <p>Advanced parameter Accuracy currently applies only to two of the three result images.</p> <p>Recommended words to include in the prompt: woman/girl/man/boy</p>"},{"location":"Flows/Photomaker_2/#examples","title":"Examples","text":"<p>The images of <code>Albert Einstein</code>, <code>Avril Lavigne</code>, and <code>Tim Cook</code> were taken from the Internet and used as a base.</p> <p> </p> <pre><code>photo of a very happy man\n</code></pre> <ul> <li>Style: Neopunk</li> </ul> <p> </p> <pre><code>photo of a warrior girl\n</code></pre> <ul> <li>Style: No Style</li> </ul> <p> </p> <pre><code>photo of an angry ancient soldier man\n</code></pre> <ul> <li>Style: Photographic (Default)</li> </ul>"},{"location":"Flows/Playground_2_5_aesthetic/","title":"Aesthetic images (Playground 2.5)","text":"<p>The flow focuses on three key improvements: enhancing color and contrast, generating images across multiple aspect ratios, and aligning outputs with human aesthetic preferences.</p> <p>It demonstrates superior performance over previous models and commercial systems in terms of aesthetic quality, especially in generating vibrant colors, accommodating different aspect ratios, and capturing fine details in human-centric images.</p> <p>Playground v2.5 outperforms widely-used models and even some closed-source systems in user studies focusing on aesthetic preferences.</p> <p>Supports various aspect ratios.</p> <p>Supports fast generation using the Align Steps technique</p>"},{"location":"Flows/Playground_2_5_aesthetic/#examples","title":"Examples","text":"<p>The second is an image with the \"fast run\" option</p> <p> </p> <pre><code>girl in suite looking at viewer, high quality, 8k, bright colors\n</code></pre> <p> </p> <pre><code>cat in suite looking at viewer, high quality, 8k, bright colors\n</code></pre> <p> </p> <pre><code>Dragon in forest, vivid colors\n</code></pre>"},{"location":"Flows/Playground_2_5_prometheus/","title":"Prometheus (Playground 2.5)","text":"<p>PrometheusV is presumed to be the first full rank finetune of Playground v2.5, developed by the creator of the Proteus model. This text-to-image generation model has been specifically adapted to enhance accessibility for the open-source community.</p> <p>PrometheusV1 represents a significant effort to make advanced text-to-image generation more accessible to the open-source community. Built upon the Playground v2.5 architecture, it has undergone a full rank finetune using an extensive dataset of over 400,000 images from the Proteus collection.</p> <p>A key aspect of its development was the removal of custom sampling methods through brute force techniques at scale, allowing the model to work more seamlessly with standard open-source tools and pipelines. Additionally, PrometheusV1 has been made backwards compatible with most SDXL LoRAs and tools.</p> <p>This approach aims to balance the model's performance capabilities with wider compatibility and ease of use. Users can expect outputs that reflect the model's intensive training on the large Proteus dataset while benefiting from improved interoperability with common open-source frameworks and existing SDXL ecosystem.</p> <p>Supports various aspect ratios.</p>"},{"location":"Flows/Playground_2_5_prometheus/#examples","title":"Examples","text":"<pre><code>portrait of gothic girl in suite looking at viewer, darkness, high quality\n</code></pre> <pre><code>close up portrait of devil in rage, high detail, ultra quality\n</code></pre> <ul> <li>steps: 40</li> </ul> <pre><code>the kindest kitten with wings, oil painting, high detail, soft colors\n</code></pre> <ul> <li>steps: 40</li> </ul>"},{"location":"Flows/SDXL_Lighting/","title":"SDXL Lighting","text":"<p>SDXL-Lightning is a fast text-to-image generation model. It can generate high-quality 1024px images in a few steps.</p>"},{"location":"Flows/SDXL_Lighting/#examples","title":"Examples","text":"<pre><code>A girl smiling\n</code></pre> <pre><code>lighting hero, anime\n</code></pre> <pre><code>portrait angry bear looking at viewer, vivid colours\n</code></pre>"},{"location":"Flows/SketchPortrait/","title":"Sketch Portrait","text":"<p>Quick creation of an anime sketch from a photograph of a person.</p> <p>Prompt is optional, something like emotions can be used there: smile, sad, serious, etc.</p> <p>Part of the flow runs on the CPU, part on the GPU, the flow is very fast and convenient for everyday use.</p>"},{"location":"Flows/SketchPortrait/#examples","title":"Examples","text":"<p>The input files were taken from the Internet and used photographs of <code>Shakira</code>, <code>Steve Jobs</code> and <code>Eminem</code>.</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"Flows/Stable_Cascade/","title":"Stable Cascade","text":"<p>This flow works much better with text rendering, and supports repeated rendering to generate images in increased resolution with more detail.</p> <p>Suitable for various fairy-tale or cartoon images or for generating postcards.</p> <ul> <li> <p>One pass image resolution: 1024x576</p> </li> <li> <p>Two pass image resolution: 1536x864</p> </li> <li> <p>Three pass image resolution: 2048x1152</p> </li> </ul>"},{"location":"Flows/Stable_Cascade/#examples","title":"Examples","text":"<pre><code>portrait of bee, high details, 8k, vivid colors, contrast light\n</code></pre> <pre><code>dolphin at sea, dawn, high details, 8k, vivid colors, contrast light\n</code></pre> <ul> <li>Second Pass: false</li> </ul> <pre><code>girl with sign 'Cascade', high details, 8k, cinematic\n</code></pre>"},{"location":"Flows/SupirUpscaler/","title":"SUPIR Upscaler","text":"<p>This workflow is added mostly for research purposes, it is still in development.</p> <p>Memory requirements(both VRAM and RAM) are directly related to the input image resolution.</p> <p>Currently, for macOS runners <code>Diffusion type</code> must be set to fp32.</p> <ul> <li><code>Low memory mode</code>: reduces the size of processed tiles to 256.</li> </ul> <p>Note</p> <p>If you have a very small input image and the result is less than 1024 (512 for low memory mode) pixels in width or height, tiles should be disabled.</p> <p>From ComfyUI-SUPIR repo:</p> <pre><code>Memory requirements are directly related to the input image resolution.\nIn my testing I was able to run 512x512 to 1024x1024 with a 10GB 3080 GPU,\nand other tests on 24GB GPU to up 3072x3072.\n\nSystem RAM requirements are also hefty, don't know numbers\nbut I would guess under 32GB is going to have issues, tested with 64GB.\n</code></pre>"},{"location":"Flows/SupirUpscaler/#examples","title":"Examples","text":"<p>This Upscaler is still in development stage, results may be get better.</p> <p>We specifically place one portrait example where results is not perfect.</p> <p>But for many tests we performed - portrait scaling is shiny compared to older scaling methods.</p> <p>Image of a classic car:</p> <p></p> <p></p> <p>Jackie Chan portrait:</p> <p></p> <p></p> <p>Shakira:</p> <p></p> <p></p>"},{"location":"Flows/VintagePortrait/","title":"Vintage Portrait","text":"<p>Create a vintage 20th century portrait from a photo of a person.</p> <p>Prompt is required, simplest examples is: [portrait of a girl, cinematic, masterpiece[</p> <p>Person's face pose is optional.</p> <p>Part of the flow runs on the CPU, part on the GPU, the flow is quite fast and convenient for everyday use.</p>"},{"location":"Flows/VintagePortrait/#examples","title":"Examples","text":"<p>As input files, the photos of <code>Bruce Lee</code> and <code>Shakira</code> were taken from the Internet and used.</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"FlowsDeveloping/comfyui_vix_migration/","title":"ComfyUI to Visionatrix migration","text":"<p>If you want to adopt your ComfyUI workflow to use in Visionatrix, you can use this guide to help you do so. There are a few steps you need to follow.</p>"},{"location":"FlowsDeveloping/comfyui_vix_migration/#1-install-comfyui-visionatrix-custom-nodes","title":"1. Install ComfyUI-Visionatrix custom nodes","text":"<p>First, it is recommended to install our custom ComfyUI-Visionatrix nodes. Otherwise, you will have to use custom nodes titles which will be parsed by Visionatrix.</p> <pre><code>git clone https://github.com/Visionatrix/ComfyUI-Visionatrix.git\n</code></pre> <p>Note</p> <p>You can do the required migration via nodes titles, which is less convenient. The node title must be like this: <code>input;Display Name;optional;advanced;order=1;custom_id=custom_name</code>.</p>"},{"location":"FlowsDeveloping/comfyui_vix_migration/#2-define-the-input-params","title":"2. Define the input params","text":"<p>Visionatrix UI aims simplicity and clarity. Define the most important input params of your ComfyUI workflow to extract them to the Visionatrix UI as inputs, for example:</p> <ul> <li>prompt (textarea)</li> <li>negative prompt (textarea)</li> <li>prompt strength (range)</li> <li>some logic toggles (checkbox)</li> <li>input files (file)</li> </ul> <p>For that you will need to attach our custom nodes as adapters to your nodes receiving these inputs that will be filled by the user from the Visionatrix UI.</p> <p>As example, you can have a look at our list of worklows adopted to the new format.</p> <p>Note</p> <p>The list of available nodes can be found in the readme of the ComfyUI-Visionatrix repository.</p>"},{"location":"FlowsDeveloping/comfyui_vix_migration/#21-node-to-input-mapping-via-title-string","title":"2.1 Node to Input mapping via title string","text":"<p>Alternatively, Visionatrix supports other Nodes mapping as an input param via node title string separated by semicolon.</p> <p>The nodes titles starting with <code>input;</code> keyword are considered input parameters to Visionatrix.</p> <p>The parameters list:</p> <ul> <li><code>input</code> - keyword to define the input param</li> <li><code>Display Name</code> - positional parameter, the name of the input field     displayed in the UI</li> <li><code>optional</code> - if present, the optional field is set to True</li> <li><code>advanced</code> - if present, the advanced field is set to True</li> <li><code>order=1</code> - the order of the input param in the UI</li> <li><code>custom_id=custom_name</code> - the custom id of the input param</li> </ul>"},{"location":"FlowsDeveloping/comfyui_vix_migration/#22-defining-file-inputs","title":"2.2 Defining file inputs","text":"<ul> <li> <p><code>LoadImage</code> - default ComfyUI image loader node as image file input     field. As required title: <code>input;Input image;order=1</code>, or optional     advanced: <code>input;Optional helper image;optional;advanced;order=20</code>;</p> <p>Note</p> <p>We recommend to always define <code>custom_id</code> value as it greatly helps to have a constant name for input parameter for API. Like: <code>input;Person's face;order=1;custom_id=person_face</code></p> </li> <li> <p>You can make a mask from <code>LoadImage</code> using <code>mask</code> word. When you do so you need to specify <code>source_input_name</code> which point to <code>custom_id</code> of input for which this mask belongs.</p> <p>Full input for inpainting and mask definition will be:</p> <pre><code>`input;Image to redraw;order=1;custom_id=source_image;`\n`input;Mask to redraw;order=2;custom_id=mask_redraw;mask;source_input_name=source_image`\n</code></pre> </li> </ul>"},{"location":"FlowsDeveloping/comfyui_vix_migration/#3-map-the-models-for-automatic-download","title":"3. Map the models for automatic download","text":"<p>Visionatrix simplifies and automates the process of downloading the models.</p> <p>You need to ensure that models used in workflow are known to Visionatrix, see models catalog</p>"},{"location":"FlowsDeveloping/comfyui_vix_migration/#4-build-the-list-of-available-flows","title":"4. Build the list of available flows","text":"<p>The last step is to build the list of available flows in the Visionatrix UI. Follow the steps described in options.py file for <code>FLOWS_URL</code> and <code>MODELS_CATALOG_URL</code> to enable Visionatrix local workflows development mode:</p> <p>Create a zip with adjusted/new flows:</p> <pre><code>cd ../VixFlowsDocs &amp;&amp; zip -r ../Visionatrix/flows.zip flows &amp;&amp; cd ../Visionatrix\n</code></pre> <p>And uncomment appropriate code lines in options.py file to use local versions of the flows.</p>"},{"location":"FlowsDeveloping/comfyui_vix_migration/#5-verify-and-test-the-workflow","title":"5. Verify and test the workflow","text":"<p>Last step is to run Visionatrix and set up your workflow to verify that everything works as expected.</p>"},{"location":"FlowsDeveloping/gated_models/","title":"Gated Models","text":"<p>Sometimes, the model you want to use requires authentication to access it. These are referred to as Gated Models.</p> <p>Flows with such models are distinctly marked in the Visionatrix UI.</p> <p>To install such a flow, you need to provide an <code>Access Token</code> for HuggingFace or an <code>API Key</code> for CivitAI.</p>"},{"location":"FlowsDeveloping/gated_models/#huggingface-token","title":"HuggingFace Token","text":"<p>Steps to access gated models from HuggingFace:</p> <ol> <li>Register on HuggingFace if you are not already registered.</li> <li>Generate an access token in the settings of HuggingFace (click on your icon \u2192 Settings \u2192 Access Tokens).</li> <li>Click <code>Set Permissions</code> for the token after generation and select <code>Read access to contents of all public gated repos you can access</code>.</li> <li>Enter this access token in the Visionatrix settings.</li> <li>Gain access to the model on your account by visiting its page (you can click on the model from the Visionatrix UI) and filling out the required form.</li> </ol>"},{"location":"FlowsDeveloping/gated_models/#civitai-api-key","title":"CivitAI API Key","text":"<p>Steps to access gated models from CivitAI:</p> <ol> <li>Register on CivitAI if you are not already registered.</li> <li>Create an API key in the settings of CivitAI (click on your icon \u2192 Add API Key).</li> <li>Enter this API key in the Visionatrix settings.</li> <li>Gain access to the model on your account by visiting its page (you can click on the model from the Visionatrix UI) and filling out the required form.</li> </ol>"},{"location":"FlowsDeveloping/gated_models/#connecting-a-worker-to-process-flows-with-gated-models","title":"Connecting a Worker to Process Flows with Gated Models","text":"<p>If you want to connect your own worker to process flows with gated models, note that user workers cannot receive global access tokens from the server to prevent leaks. You have two options:</p> <ol> <li>Download the model yourself and place it in the folder specified in <code>models_catalog.json</code> under the <code>filename</code> or <code>types</code> keys.</li> <li>Set the <code>HF_AUTH_TOKEN</code> environment variable with your own public access token. The worker will then be able to install flows with gated models from HuggingFace.</li> <li>For CivitAI, set the environment variable <code>CA_API_KEY</code>.</li> </ol>"},{"location":"FlowsDeveloping/models_catalog/","title":"Adding New Model to Catalog","text":""},{"location":"FlowsDeveloping/models_catalog/#introduction","title":"Introduction","text":"<p>Visionatrix uses a <code>models_catalog.json</code> file to automatically map nodes in ComfyUI workflows to their corresponding models, ensuring a seamless user experience.</p> <p>If you use a model that is missing in the current catalog, you can now easily add it using our new Model Catalog Editor tool.</p> <p>This tool helps you create consistent and accurate entries in <code>models_catalog.json</code> by guiding you through setting the model\u2019s URL, homepage, filename, hash, and classification (\"types\").</p>"},{"location":"FlowsDeveloping/models_catalog/#optional-auth-tokens","title":"Optional Auth Tokens","text":"<p>If you have authentication tokens for Hugging Face or CivitAI, the tool can use them to fetch metadata and check gated models. It will attempt to read these tokens from the Visionatrix database if available.</p> <p>The script looks for the database in the <code>../Visionatrix</code> directory, so if both repositories are cloned in the same parent directory, the setup should work seamlessly.</p> <p>Note</p> <p>Lack of access to the database or missing tokens does not prevent adding models, but certain features (like checking gated models) may be limited.</p>"},{"location":"FlowsDeveloping/models_catalog/#launching-the-editor","title":"Launching the Editor","text":"<p>The <code>models_catalog_editor.py</code> file is located in the <code>VixFlowsDocs</code> repository at its root. You will also find a <code>requirements_catalog_editor.txt</code> file there. To start:</p> <ol> <li>Install Dependencies (if needed):</li> </ol> <pre><code>pip install -r requirements_catalog_editor.txt\n</code></pre> <ol> <li>Run the Editor:</li> </ol> <pre><code>python models_catalog_editor.py\n</code></pre> <p>This opens a GUI window:</p> <p></p>"},{"location":"FlowsDeveloping/models_catalog/#using-the-model-catalog-editor","title":"Using the Model Catalog Editor","text":""},{"location":"FlowsDeveloping/models_catalog/#step-1-provide-the-model-source-url","title":"Step 1: Provide the Model Source URL","text":"<p>In the \"URL\" field, enter the direct link to your model. Supported sources:</p> <ul> <li> <p>Hugging Face: e.g., <code>https://huggingface.co/{user}/{repo}/blob/main/model.safetensors</code> The editor automatically corrects <code>/blob/</code> links to <code>/resolve/</code> if necessary.</p> </li> <li> <p>CivitAI: Provide a link that includes a <code>modelVersionId</code> query parameter or a link to a model/version page. The tool will attempt to fetch metadata and files associated with that model.</p> </li> </ul> <p>Click Process. The editor then tries to:</p> <ul> <li>Fetch a homepage URL.</li> <li>Propose a default filename.</li> <li>Check if the model is gated (requires auth token).</li> <li>For CivitAI, it lists all available files and their hashes, prompting you to choose one if multiple are found. It also attempts to determine the correct model <code>type</code> from the metadata.</li> </ul>"},{"location":"FlowsDeveloping/models_catalog/#step-2-confirm-or-edit-the-download-url-homepage-and-filenames","title":"Step 2: Confirm or Edit the Download URL, Homepage, and Filenames","text":"<ul> <li>Download URL: The tool sets this automatically for known sources. You can adjust it if needed.</li> <li>Homepage: For Hugging Face, this is usually the repository root. For CivitAI, it's the model\u2019s main page. You can also enter a custom homepage if necessary.</li> <li>Filenames:   The editor attempts to determine a good filename. If your model came from Hugging Face and also exists on CivitAI, you might see a \"HugFace name\" and a \"CivitAI name\".   If the suggested filenames are not suitable (e.g., too generic like <code>model.safetensors</code>), provide a \"Force Filename\" to ensure uniqueness and clarity.</li> </ul>"},{"location":"FlowsDeveloping/models_catalog/#step-3-verify-the-hash","title":"Step 3: Verify the Hash","text":"<p>The editor tries to fetch a SHA256 hash for the model:</p> <ul> <li>For Hugging Face models with a supported configuration, it reads the <code>X-Linked-ETag</code> header as a hash.</li> <li>For CivitAI models, it uses the provided file hash from the metadata.</li> </ul> <p>If the hash is not found, enter it manually in the \"Hash\" field. The hash is crucial for ensuring model integrity and facilitating quick checks by Visionatrix.</p>"},{"location":"FlowsDeveloping/models_catalog/#step-4-set-model-types","title":"Step 4: Set Model \"Types\"","text":"<p>\"Types\" determines where the model file will be stored inside ComfyUI\u2019s directory structure. Common types include:</p> <ul> <li><code>checkpoints</code></li> <li><code>diffusion_models</code></li> <li><code>loras</code></li> <li><code>controlnet</code></li> <li><code>embeddings</code></li> <li><code>vae</code></li> <li>... and more.</li> </ul> <p>The tool tries to infer a type from the model\u2019s metadata. However, for certain models (like SD3.5 or Flux models), the correct type may not be determined automatically. In such cases, you must manually select the correct type from the checkboxes.</p> <p>Tip: If unsure, consider:</p> <ul> <li><code>diffusion_models</code> or <code>checkpoints</code> for base diffusion models.</li> <li><code>loras</code> for LoRA-based models.</li> <li><code>controlnet</code> for ControlNet-based models.</li> <li><code>embeddings</code> for textual inversion embeddings.</li> </ul>"},{"location":"FlowsDeveloping/models_catalog/#step-5-set-gated-if-needed","title":"Step 5: Set Gated (if Needed)","text":"<p>If the model is gated (e.g., private or requires a Hugging Face token to download), check the \"Gated\" box. This ensures Visionatrix knows it needs an authorization token for downloading.</p>"},{"location":"FlowsDeveloping/models_catalog/#step-6-define-the-regexes","title":"Step 6: Define the Regexes","text":"<p>Regexes help Visionatrix identify which model entry applies to a given node in a ComfyUI workflow. You can set:</p> <ul> <li><code>class_type</code> regex: Matches the ComfyUI node\u2019s <code>class_type</code>.</li> <li><code>input_name</code> regex: Matches the input parameter name of the node parameter that holds the model filename.</li> <li><code>input_value</code> regex: Required to match the actual input value from the workflow (e.g., the filename or part of it).</li> </ul> <p>Important: - <code>input_value</code> is mandatory. It should match the final filename or a portion of it. - Use a pattern that is flexible enough to capture variations in filenames, but not so broad it conflicts with other models.</p> <p>For example, if your filename is <code>my-special-model.safetensors</code>, a suitable <code>input_value</code> might be:</p> <pre><code>(?i)(?:[^\\/\\\\]*[\\/\\\\]?)?my-special-model\\.safetensors$\n</code></pre> <p>If you have multiple filenames (like a Hugging Face name and a CivitAI name), the tool tries to create a regex that matches them all. Adjust the regex if necessary to ensure uniqueness and correctness.</p>"},{"location":"FlowsDeveloping/models_catalog/#step-7-save-the-entry","title":"Step 7: Save the Entry","text":"<p>Once you have verified all fields:</p> <ul> <li>Click Save.</li> <li>Choose or confirm a unique model name key. The tool ensures no conflicts with existing keys. If there's a hash conflict, you can overwrite or rename the key.</li> <li>On successful save, the model entry is added to <code>models_catalog.json</code>.</li> </ul>"},{"location":"FlowsDeveloping/models_catalog/#conclusion","title":"Conclusion","text":"<p>With this utility, adding new models has become easy and efficient.</p> <p>After saving your changes locally, consider sharing your <code>models_catalog.json</code> updates by submitting a pull request to the VixFlowsDocs repository.</p>"},{"location":"FlowsDeveloping/technical_information/","title":"Technical Information","text":""},{"location":"FlowsDeveloping/technical_information/#bundled-comfyui-nodes","title":"Bundled ComfyUI nodes","text":"<p>Visionatrix by default install and reinstall on <code>update</code> some nodes that are required by flows we provide as examples.</p> <p>You can find file with it here: basic_node_list.py</p> <p>Note</p> <p>Starting from the Visionatrix <code>2.0</code> version we had switched to the ComfyUI-Manager.</p> <p>All nodes are installed from the Comfy-Registry or their original repositories.</p> <p>You could easily update Nodes yourself if needed or install new ones.</p> <p>If after updating via ComfyUI-Manager some of the nodes stopped working, we recommend running the command:</p> <pre><code>`python3 -m visionatrix update`\n</code></pre> <p>This command will perform a re-instalaltion of the nodes that are included in the Visionatrix package to the original versions that were supplied with this version of Visionatrix.</p>"},{"location":"FlowsDeveloping/technical_information/#workflows-storage","title":"Workflows Storage","text":"<p>All public flows are located in the VixFlowsDocs repository.</p> <p>The repository consists of a development branch main and a set of branches version-X.Y:</p> <ul> <li>version-0.5</li> <li>version-0.6</li> <li>...</li> <li>version-1.0</li> <li>version-1.1</li> <li>main</li> </ul> <p>Sets of public workflows are packaged in the root of the documentation and have the following form:</p> <ul> <li>flows-0.5.zip</li> <li>flows-0.6.zip</li> <li>...</li> <li>flows-1.0.zip</li> <li>flows-1.1.zip</li> <li>flows.zip</li> </ul> <p>The development version of Visionatrix fetches the <code>flows.zip</code> archive by default.</p> <p>Release versions of Visionatrix fetch sets of flows for their version.</p>"},{"location":"FlowsDeveloping/technical_information/#configuring-flows-sources","title":"Configuring Flows Sources","text":"<p>The <code>FLOWS_URL</code> variable in Visionatrix has the default value of:</p> <pre><code>FLOWS_URL=https://visionatrix.github.io/VixFlowsDocs/\n</code></pre> <p>You can specify multiple URLs or paths to flow archives by separating them with semicolons <code>;</code>.</p> <p>When an element in the FLOWS_URL ends with <code>/</code>, Visionatrix fetches an archive with flows appropriate for its version:</p> <ul> <li>For development versions, it fetches <code>flows.zip</code>.</li> <li>For release versions, it fetches <code>flows-X.Y.zip</code>, where <code>X.Y</code> matches the major and minor Visionatrix version numbers.</li> </ul>"},{"location":"FlowsDeveloping/technical_information/#examples","title":"Examples","text":"<ol> <li> <p>Default Configuration:</p> <pre><code>FLOWS_URL=https://visionatrix.github.io/VixFlowsDocs/\n</code></pre> <p>Visionatrix will fetch flows from the official repository corresponding to its version.</p> </li> <li> <p>Custom Flow Sources:</p> <pre><code>FLOWS_URL=https://visionatrix.github.io/VixFlowsDocs/;https://example.com/custom_flows.zip;/local/path/flows.zip\n</code></pre> <p>Visionatrix will fetch flows from:</p> <ul> <li>The official repository.</li> <li>A custom online archive at <code>https://example.com/custom_flows.zip</code>.</li> <li>A local archive at <code>/local/path/flows.zip</code>.</li> </ul> </li> </ol>"},{"location":"FlowsDeveloping/technical_information/#flow-merging-and-versioning","title":"Flow Merging and Versioning","text":"<ul> <li> <p>When multiple flows have the same name across different sources, Visionatrix will:</p> <ul> <li>Prefer the flow with the highest version number.</li> <li>If versions are equal, the flow from the first source in the <code>FLOWS_URL</code> list takes precedence.</li> </ul> </li> <li> <p>This allows you to override or supplement the default flows with custom ones.</p> </li> </ul>"},{"location":"FlowsDeveloping/technical_information/#notes","title":"Notes","text":"<ul> <li> <p>Local Paths: You can specify local paths to flow archives, which is useful during development or when working offline.</p> </li> <li> <p>URL Endings:</p> <ul> <li> <p>If a URL ends with <code>/</code>, Visionatrix automatically appends the appropriate <code>flows.zip</code> or <code>flows-X.Y.zip</code> based on its version.</p> </li> <li> <p>If a URL points directly to an archive (e.g., <code>https://example.com/custom_flows.zip</code>), Visionatrix will use that specific file.</p> </li> </ul> </li> </ul>"},{"location":"FlowsDeveloping/technical_information/#models-storage","title":"Models Storage","text":"<p>All public models catalogs are located in the VixFlowsDocs repository.</p> <p>Similar to workflows, the repository consists of a development branch main and a set of branches version-X.Y:</p> <ul> <li>version-0.5</li> <li>version-0.6</li> <li>...</li> <li>version-1.0</li> <li>version-1.1</li> <li>main</li> </ul> <p>The models catalogs are available in the root of the documentation and have the following form:</p> <ul> <li>models_catalog-0.5.json</li> <li>models_catalog-0.6.json</li> <li>...</li> <li>models_catalog-1.0.json</li> <li>models_catalog-1.1.json</li> <li>models_catalog.json</li> </ul> <p>The development version of Visionatrix fetches the <code>models_catalog.json</code> by default.</p> <p>Release versions of Visionatrix fetch the models catalog for their version.</p>"},{"location":"FlowsDeveloping/technical_information/#configuring-models-catalog-sources","title":"Configuring Models Catalog Sources","text":"<p>The <code>MODELS_CATALOG_URL</code> variable in Visionatrix has the default value of:</p> <pre><code>MODELS_CATALOG_URL=https://visionatrix.github.io/VixFlowsDocs/\n</code></pre> <p>You can specify multiple URLs or paths to catalogs by separating them with semicolons <code>;</code>.</p> <p>When an element in the MODELS_CATALOG_URL ends with <code>/</code>, Visionatrix fetches the catalog appropriate for its version:</p> <ul> <li>For development versions, it fetches <code>models_catalog.json</code>.</li> <li>For release versions, it fetches <code>models_catalog-X.Y.json</code>, where <code>X.Y</code> matches the major and minor Visionatrix version numbers.</li> </ul>"},{"location":"FlowsDeveloping/technical_information/#examples_1","title":"Examples","text":"<ol> <li> <p>Default Configuration:</p> <pre><code>MODELS_CATALOG_URL=https://visionatrix.github.io/VixFlowsDocs/\n</code></pre> <p>Visionatrix will fetch the models catalog from the repository corresponding to its version.</p> </li> <li> <p>Custom Models Catalog Sources:</p> <pre><code>MODELS_CATALOG_URL=https://visionatrix.github.io/VixFlowsDocs/;https://example.com/custom_models_catalog.json;/local/path/models_catalog.json\n</code></pre> <p>Visionatrix will fetch models catalogs from:</p> <ul> <li>The official repository.</li> <li>A custom online catalog at <code>https://example.com/custom_models_catalog.json</code>.</li> <li>A local catalog at <code>/local/path/models_catalog.json</code>.</li> </ul> </li> </ol>"},{"location":"FlowsDeveloping/technical_information/#models-merging-and-versioning","title":"Models Merging and Versioning","text":"<ul> <li> <p>When multiple models have the same name across different sources, Visionatrix will:</p> <ul> <li>Prefer the model from the source listed later in the <code>MODELS_CATALOG_URL</code> variable.</li> <li>Allow custom catalogs to override or supplement default models.</li> </ul> </li> </ul>"},{"location":"FlowsDeveloping/technical_information/#notes_1","title":"Notes","text":"<ul> <li> <p>Local Paths: You can specify local paths to models catalogs, which is useful during development or when working offline.</p> </li> <li> <p>URL Endings:</p> <ul> <li> <p>If a URL ends with <code>/</code>, Visionatrix automatically appends the appropriate <code>models_catalog.json</code> or <code>models_catalog-X.Y.json</code> based on its version.</p> </li> <li> <p>If a URL points directly to a catalog (e.g., <code>https://example.com/custom_models_catalog.json</code>), Visionatrix will use that specific file.</p> </li> </ul> </li> </ul>"},{"location":"FlowsDeveloping/vix_workflows/","title":"Vix Workflows","text":""},{"location":"FlowsDeveloping/vix_workflows/#introduction","title":"Introduction","text":"<p>ComfyUI workflows are designed for developers and those interested in diffusion processes.</p> <p>Visionatrix workflows are created on top of ComfyUI workflows for easy deployment and straightforward use.</p> <p>Currently, there are two main issues with using ComfyUI flows for the public:</p> <ol> <li> <p>It's unclear where to get the model from and how to deploy/install it:</p> <p>deployment/installation issue</p> </li> <li> <p>Without some experience, it's unclear how to just provide inputs to simple get results:</p> <p>usability issue</p> </li> </ol>"},{"location":"FlowsDeveloping/vix_workflows/#automatic-models-mapping","title":"Automatic models mapping","text":"<p>To address the first issue with model mapping, Visionatrix includes a models_catalog.json file.</p> <p>By default, it is taken and updated from the Visionatrix repository on GitHub, in case you add a new flow and need to add new model mappings you can change its path using an environment variable to a local file path or add additional places from where to fetch it.</p> <p>Note</p> <p>UI for easily adding models without going into too much detail, you can find it on this documentation page.</p> <p>The file structure consists of a set of objects, each describing a ComfyUI Node class that loads or uses a model.</p> <pre><code>\"InstantID-ControlNet\": {\n    \"regexes\": [\n      {\n        \"class_name\": \"ControlNetLoader\",\n        \"input_value\": \"^(?=.*(?i:instantid)).*\"\n      }\n    ],\n    \"url\": \"https://huggingface.co/InstantX/InstantID/resolve/main/ControlNetModel/diffusion_pytorch_model.safetensors\",\n    \"homepage\": \"https://huggingface.co/InstantX/InstantID\",\n    \"hash\": \"c8127be9f174101ebdafee9964d856b49b634435cf6daa396d3f593cf0bbbb05\",\n    \"types\": [\n      \"controlnet\"\n    ],\n    \"filename\": \"instantid-controlnet.safetensors\"\n  }\n</code></pre>"},{"location":"FlowsDeveloping/vix_workflows/#regexes","title":"\"regexes\"","text":"<p>Regexes are used to understand if this record related to the specified model from the ComfyUI workflow.</p> <p><code>\"input_name\"</code>, <code>\"class_name\"</code>, and <code>\"input_value\"</code> are supported, both together and separately.</p> <p>Note</p> <p>If these conditions prove insufficient, please create an issue and we will find a solution together.</p>"},{"location":"FlowsDeveloping/vix_workflows/#types","title":"\"types\"","text":"<p>This field lists one or more categories the model belongs to (e.g., <code>text_encoders</code>, <code>ipadapter</code>). It determines the folder where the model will be saved.</p> <p>If <code>types</code> is empty or missing, the <code>filename</code> is assumed to be located at the root of the ComfyUI folder.</p> <p>Together, <code>types</code> and <code>filename</code> should provide enough information to correctly place the model.</p>"},{"location":"FlowsDeveloping/vix_workflows/#filename","title":"\"filename\"","text":"<p>Overrides the default file name for the model.</p> <p>This is particularly useful when the model has a generic name (e.g., <code>\"model.safetensors\"</code>) that could conflict with others.</p> <p>Using a unique name avoids such conflicts.</p>"},{"location":"FlowsDeveloping/vix_workflows/#url","title":"\"url\"","text":"<p>Indicates where to download the model from if it is not already present.</p> <p>It is preferable for the model to be hosted on Hugging Face, but <code>civitai.com</code> is also supported.</p>"},{"location":"FlowsDeveloping/vix_workflows/#homepage","title":"\"homepage\"","text":"<p>An optional field with a link to the model's home page where you can view the license.</p>"},{"location":"FlowsDeveloping/vix_workflows/#hash","title":"\"hash\"","text":"<p>The SHA256 hash of the model. Used to verify the integrity of the model and check for download errors.</p>"},{"location":"FlowsDeveloping/vix_workflows/#vix-workflow-overview","title":"Vix workflow overview","text":"<p>In the Visionatrix the workflow consists of a single file: <code>flow_name.json</code>, which is a ComfyUI workflow file adopted to Visionatrix.</p> <p>Note</p> <p>The main difference between Visionatrix and ComfyUI:</p> <p>A task is created with a single request, which includes both incoming text parameters and input files.</p> <p>The flow metadata fields described below are filled in the <code>VixUi-WorkflowMetadata</code> node.</p>"},{"location":"FlowsDeveloping/vix_workflows/#name","title":"\"name\"","text":"<p>The name of the workflow. It usually matches the name of the file with workflow.</p>"},{"location":"FlowsDeveloping/vix_workflows/#display_name","title":"\"display_name\"","text":"<p>Used in the UI to display the name of the flow.</p>"},{"location":"FlowsDeveloping/vix_workflows/#description","title":"\"description\"","text":"<p>A brief description of the flow for user display.</p>"},{"location":"FlowsDeveloping/vix_workflows/#author","title":"\"author\"","text":"<p>The name of the ComfyUI flow author or the Visionatrix flow author.</p>"},{"location":"FlowsDeveloping/vix_workflows/#homepage_1","title":"\"homepage\"","text":"<p>A link that will open when clicking on the flow author's name.</p>"},{"location":"FlowsDeveloping/vix_workflows/#license","title":"\"license\"","text":"<p>The general license under which the flow can be used (to simplify understanding whether it can be used behind the API service, whether it can be used commercially, etc.)</p>"},{"location":"FlowsDeveloping/vix_workflows/#documentation","title":"\"documentation\"","text":"<p>Link to additional information about the flow.</p>"},{"location":"FlowsDeveloping/vix_workflows/#tags","title":"\"tags\"","text":"<p>A list of string tags that can be used to label the categories of the flow.</p>"},{"location":"FlowsDeveloping/vix_workflows/#input_params","title":"\"input_params\"","text":"<p>Note</p> <p>The input params are parsed automatically from the adopted ComfyUI workflow. Based on the information from this field, the Visionatrix UI dynamically displays the interface.</p> <p>Technically, this is a list of objects, where each object is one input parameter, which includes:</p> <ul> <li>\"name\" - the key(used only when <code>type</code> is equal <code>\"text\"</code>)</li> <li>\"display_name\" - the name of the parameter displayed in the UI</li> <li> <p>\"type\" - a string that can have values: <code>\"text\"</code> or <code>\"image\"</code></p> <p>Note</p> <p><code>\"video\"</code> and <code>\"audio\"</code> types will be added as soon as there is the first Workflow requiring it.</p> </li> <li> <p>\"optional\" - indicates whether the parameter is optional. If an     optional field is not provided, the backend will fill it in automatically.</p> </li> <li>\"advanced\" - used only in the UI, shows whether the field should     be hidden by default (we do not want to overload the interface for regular users)</li> <li> <p>\"default\" - the field value to initiate.</p> <p>Note</p> <p>Used for both UI and backend, but not mandatory even for optional fields (as in the ComfyUI flow, the Node value is still set)</p> </li> <li> <p>\"comfy_node_id\" - a field only for the backend, which defines what to do with this value (where to use it in the ComfyUI Flow)</p> </li> </ul>"},{"location":"FlowsDeveloping/vix_workflows/#required_memory_gb","title":"\"required_memory_gb\"","text":"<p>This field indicates the amount of (video) memory in gigabytes required for the flow to work.</p> <p>By default, in Visionatrix, all flows not supported by the available hardware are hidden.</p>"},{"location":"FlowsDeveloping/vix_workflows/#calculating-required-memory","title":"Calculating <code>Required Memory</code>","text":"<p>To determine the appropriate <code>required_memory_gb</code> value for a flow (e.g., on a GPU with 24 GB of memory), follow these steps:</p>"},{"location":"FlowsDeveloping/vix_workflows/#adjusting-for-different-gpu-memory","title":"Adjusting for Different GPU Memory","text":"<p>If your GPU has less memory (e.g., 16 GB), reduce the calculated values accordingly (subtract 8 GB from the original values for a 24 GB card).</p>"},{"location":"FlowsDeveloping/vix_workflows/#steps-to-measure-memory-usage","title":"Steps to Measure Memory Usage","text":"<ol> <li> <p>Disable Smart Memory Management    Run ComfyUI with the following argument:    <code>--disable-smart-memory --reserve-vram=17.2</code></p> </li> <li> <p>Enable Execution Settings    Inside Visionatrix when launching Flow, navigate to:    Advanced Options -&gt; Execution Settings    Set the variables <code>X-WORKER-UNLOAD-MODELS</code> and <code>X-WORKER-EXECUTION-PROFILER</code> to <code>1</code>. Check the box for \"Enable Execution Settings\".</p> </li> <li> <p>Execute the Flow    Launch the task with \"Execution Settings\" enabled. After the task completes, click the ellipsis under the task and select \"Execution Details\".</p> </li> <li> <p>Review Maximum Memory Usage    In the Execution Details, look for a value labeled <code>\"max_memory_usage\"</code>. For example:    <code>\"max_memory_usage\": 3800.11</code>    This value represents the maximum memory usage in megabytes for the task.</p> </li> <li> <p>Convert Memory Usage to Gigabytes    Ensure that the <code>\"max_memory_usage\"</code> value does not exceed the desired <code>required_memory_gb</code>. Use this value to set the field appropriately.</p> </li> </ol>"},{"location":"FlowsDeveloping/vix_workflows/#important-notes","title":"Important Notes","text":"<ul> <li>For accurate measurements, ComfyUI must be launched with the <code>--disable-smart-memory</code> parameter, and <code>X-WORKER-UNLOAD-MODELS</code> must be set to <code>1</code>.</li> <li>While not all nodes support the <code>--reserve-vram</code> parameter, and some nodes like <code>Supir</code> may not reflect accurate <code>max_memory_usage</code> values due to their reset behavior, this approach is still much better than no estimation.</li> </ul>"},{"location":"FlowsDeveloping/vix_workflows/#gpu-memory-settings-for-common-configurations","title":"GPU Memory Settings for Common Configurations","text":"<p>Here are recommended arguments for testing if a flow works on GPUs with specific memory configurations:</p> <ul> <li>6 GB cards: <code>--disable-smart-memory --reserve-vram=19.2</code></li> <li>8 GB cards: <code>--disable-smart-memory --reserve-vram=17.2</code></li> <li>12 GB cards: <code>--disable-smart-memory --reserve-vram=13.2</code></li> <li>16 GB cards: <code>--disable-smart-memory --reserve-vram=9.2</code></li> </ul>"},{"location":"IntegrationsManual/getting_started/","title":"Integrating Visionatrix: Getting Started","text":"<p>This guide will help you get started with programmatically interacting with Visionatrix.</p> <p>Note</p> <p>SDXL Lighting and Remove Background (Birefnet) flows should be installed on the Visionatrix instance.</p> <p>This guide only covers how to create tasks from a flow, fetch their progress, and receive the results.</p> <p>Info</p> <p>We constantly strive to make our API more comfortable to use with code generated by Claude, Qwen, or ChatGPT.</p> <p>However, this guide is primarily focused on understanding the lifespan of a task. It does not describe how to automatically create a Gradio application for the specified flow or any other such topics.</p>"},{"location":"IntegrationsManual/getting_started/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Authentication</li> <li>Task Lifecycle</li> <li>Full Working Examples in Python<ul> <li>Example 1: Using the \"SDXL Lighting\" Flow</li> <li>Example 2: Using the \"Remove Background (Birefnet)\" Flow</li> </ul> </li> </ol>"},{"location":"IntegrationsManual/getting_started/#authentication","title":"Authentication","text":"<p>Visionatrix currently supports Basic Authentication only. Depending on the mode in which Visionatrix is running, you may or may not need to provide authentication credentials:</p> <ul> <li>SERVER Mode: If Visionatrix is running in SERVER mode, you must specify your username and password in your API requests.</li> <li>DEFAULT Mode: If Visionatrix is running in DEFAULT mode, no authentication is required.</li> </ul> <p>For the purposes of this guide, we will assume that authentication is required.</p> <p>By default, we use <code>admin</code> as both the username and password in our development setups for SERVER mode when testing Visionatrix. Replace these with your actual credentials if they are different.</p>"},{"location":"IntegrationsManual/getting_started/#task-lifecycle","title":"Task Lifecycle","text":"<p>The typical lifecycle of a task in Visionatrix involves the following steps:</p> <ol> <li> <p>Creating a Task: You send a <code>PUT</code> request to the <code>/vapi/tasks/create/{name}</code> endpoint, where <code>{name}</code> is the ID of the flow you want to use. The request must use <code>multipart/form-data</code> and include the necessary parameters for the flow.</p> </li> <li> <p>For the SDXL Lighting (<code>sdxl_lighting</code>) flow, required parameters are:</p> <ul> <li><code>prompt</code> (string): The text prompt for image generation.</li> <li><code>steps_number</code> (string): The number of steps to use.</li> </ul> </li> <li> <p>Optional Parameters:</p> <ul> <li><code>negative_prompt</code> (string): The \"negative\" text prompt for image generation.</li> <li><code>seed</code> (integer): The seed for random number generation. If not specified, a random seed will be used.</li> </ul> </li> <li> <p>For the Remove Background (Birefnet) (<code>remove_background_birefnet</code>) flow, required parameters are:</p> <ul> <li><code>input_image</code> (file): The image file from which to remove the background.</li> </ul> </li> <li> <p>Other Parameters:</p> <ul> <li>There are additional optional parameters such as <code>webhook_url</code>, <code>webhook_headers</code>, <code>translate</code>, <code>group_scope</code>, etc. These parameters are not covered in this beginner guide.</li> </ul> </li> <li> <p>Checking Task Progress: After creating a task, you can check its progress using the <code>/vapi/tasks/progress/{task_id}</code> endpoint. The response includes details such as the task's <code>progress</code>, <code>error</code> (if any), and a list of <code>outputs</code>.</p> </li> <li> <p>Progress Values:</p> <ul> <li><code>0.0</code>: Task is queued and has not started yet.</li> <li>Between <code>0.1</code> and <code>99.9</code>: Task is in progress.</li> <li><code>100.0</code>: Task is completed.</li> </ul> </li> <li> <p>Error Handling:</p> <ul> <li>If the <code>error</code> field is not empty, the task has encountered an error.</li> <li>You can retry the task or investigate the issue based on the error message.</li> </ul> </li> <li> <p>Retrieving Task Results: Once a task is completed (<code>progress</code> reaches <code>100.0</code>), you can retrieve the results using the <code>/vapi/tasks/results</code> endpoint. The <code>outputs</code> from the task details contain a list of output nodes, each with a <code>comfy_node_id</code>. You should iterate over all the outputs to retrieve all results.</p> </li> <li> <p>To retrieve each result, you send a <code>GET</code> request to <code>/vapi/tasks/results</code> with the <code>task_id</code> and <code>node_id</code> (which is the <code>comfy_node_id</code> from the outputs).</p> </li> <li>The result files can then be saved locally. The format of the result file depends on the flow and the output node's type.</li> </ol> <p>Note</p> <p>We are currently in the process of automatically creating OpenAPI specifications for the flows: Flows API.</p> <p>You can easily take a look at the flow parameters there.</p>"},{"location":"IntegrationsManual/getting_started/#full-working-examples-in-python","title":"Full Working Examples in Python","text":"<p>Below are full working examples in Python using the <code>httpx</code> library. These scripts demonstrate how to create a task, check its progress, and retrieve all the results for both the <code>sdxl_lighting</code> and <code>remove_background_birefnet</code> flows.</p> <p>Before running the scripts, make sure you have the <code>httpx</code> library installed:</p> <pre><code>pip install httpx\n</code></pre>"},{"location":"IntegrationsManual/getting_started/#example-1-using-the-sdxl-lighting-flow","title":"Example 1: Using the \"SDXL Lighting\" Flow","text":"<pre><code>import httpx\nimport time\n\n# Replace with your Visionatrix server URL\nbase_url = \"http://localhost:8288\"\nusername = \"admin\"\npassword = \"admin\"\n\n\ndef create_sdxl_lighting_task():\n    # Task parameters\n    params = {\n        'prompt': 'A beautiful sunset over the mountains',\n        'steps_number': '8 steps',\n        # 'negative_prompt' is optional\n        # 'negative_prompt': 'blurry, low resolution',\n        # 'seed' is optional; if not specified, a random seed will be used\n        # 'seed': '12345',\n    }\n\n    # Convert parameters to the format expected by the 'files' parameter\n    files = {key: (None, value) for key, value in params.items()}\n\n    # Create the task\n    response = httpx.put(\n        f\"{base_url}/vapi/tasks/create/sdxl_lighting\",\n        auth=(username, password),\n        files=files\n    )\n\n    # Check if the request was successful\n    if response.status_code == 200:\n        data = response.json()\n        task_ids = data.get('tasks_ids', [])\n        if task_ids:\n            task_id = task_ids[0]\n            print(\"Task created successfully. Task ID:\", task_id)\n            return task_id\n        else:\n            print(\"No task ID returned.\")\n    else:\n        print(\"Failed to create task:\", response.text)\n    return None\n\n\ndef check_task_progress(task_id):\n    while True:\n        response = httpx.get(\n            f\"{base_url}/vapi/tasks/progress/{task_id}\",\n            auth=(username, password)\n        )\n\n        if response.status_code == 200:\n            task_details = response.json()\n            progress = task_details.get('progress', 0)\n            error = task_details.get('error', '')\n            print(f\"Task {task_id} progress: {progress}%\")\n            if error:\n                print(f\"Task {task_id} encountered an error: {error}\")\n                return None\n            if progress &gt;= 100:\n                print(\"Task completed.\")\n                outputs = task_details.get('outputs', [])\n                return outputs  # Return outputs to avoid additional server call\n        else:\n            print(\"Failed to get task progress:\", response.text)\n            return None\n\n        # Wait before polling again\n        time.sleep(5)\n\n\ndef retrieve_task_results(task_id, outputs):\n    if outputs:\n        for output in outputs:\n            node_id = output.get('comfy_node_id')\n            if node_id is not None:\n                # Retrieve the result for each output node\n                params = {\n                    'task_id': task_id,\n                    'node_id': node_id\n                }\n                result_response = httpx.get(\n                    f\"{base_url}/vapi/tasks/results\",\n                    auth=(username, password),\n                    params=params\n                )\n                if result_response.status_code == 200:\n                    # Save the result to a file\n                    result_filename = f\"result_{task_id}_{node_id}.png\"\n                    with open(result_filename, 'wb') as f:\n                        f.write(result_response.content)\n                    print(f\"Result saved to {result_filename}\")\n                else:\n                    print(f\"Failed to retrieve result for node {node_id}:\", result_response.text)\n            else:\n                print(\"Output node ID not found.\")\n    else:\n        print(\"No outputs found in task details.\")\n\n\ndef main():\n    task_id = create_sdxl_lighting_task()\n    if task_id:\n        outputs = check_task_progress(task_id)\n        if outputs is not None:\n            retrieve_task_results(task_id, outputs)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"IntegrationsManual/getting_started/#example-2-using-the-remove-background-birefnet-flow","title":"Example 2: Using the \"Remove Background (Birefnet)\" Flow","text":"<pre><code>import httpx\nimport time\n\n# Replace with your Visionatrix server URL\nbase_url = \"http://localhost:8288\"\nusername = \"admin\"\npassword = \"admin\"\ninput_image_path = \"image.jpg\"\n\n\ndef create_remove_background_task():\n    # Open the image file in binary mode\n    with open(input_image_path, 'rb') as image_file:\n        files = {\n            'input_image': image_file\n        }\n\n        # Create the task\n        response = httpx.put(\n            f\"{base_url}/vapi/tasks/create/remove_background_birefnet\",\n            auth=(username, password),\n            files=files\n        )\n\n    # Check if the request was successful\n    if response.status_code == 200:\n        data = response.json()\n        task_ids = data.get('tasks_ids', [])\n        if task_ids:\n            task_id = task_ids[0]\n            print(\"Task created successfully. Task ID:\", task_id)\n            return task_id\n        else:\n            print(\"No task ID returned.\")\n    else:\n        print(\"Failed to create task:\", response.text)\n    return None\n\n\ndef check_task_progress(task_id):\n    while True:\n        response = httpx.get(\n            f\"{base_url}/vapi/tasks/progress/{task_id}\",\n            auth=(username, password)\n        )\n\n        if response.status_code == 200:\n            task_details = response.json()\n            progress = task_details.get('progress', 0)\n            error = task_details.get('error', '')\n            print(f\"Task {task_id} progress: {progress}%\")\n            if error:\n                print(f\"Task {task_id} encountered an error: {error}\")\n                return None\n            if progress &gt;= 100:\n                print(\"Task completed.\")\n                outputs = task_details.get('outputs', [])\n                return outputs  # Return outputs to avoid additional server call\n        else:\n            print(\"Failed to get task progress:\", response.text)\n            return None\n\n        # Wait before polling again\n        time.sleep(5)\n\n\ndef retrieve_task_results(task_id, outputs):\n    if outputs:\n        for output in outputs:\n            node_id = output.get('comfy_node_id')\n            if node_id is not None:\n                # Retrieve the result for each output node\n                params = {\n                    'task_id': task_id,\n                    'node_id': node_id\n                }\n                result_response = httpx.get(\n                    f\"{base_url}/vapi/tasks/results\",\n                    auth=(username, password),\n                    params=params\n                )\n                if result_response.status_code == 200:\n                    # Save the result to a file\n                    result_filename = f\"result_{task_id}_{node_id}.png\"\n                    with open(result_filename, 'wb') as f:\n                        f.write(result_response.content)\n                    print(f\"Result saved to {result_filename}\")\n                else:\n                    print(f\"Failed to retrieve result for node {node_id}:\", result_response.text)\n            else:\n                print(\"Output node ID not found.\")\n    else:\n        print(\"No outputs found in task details.\")\n\n\ndef main():\n    task_id = create_remove_background_task()\n    if task_id:\n        outputs = check_task_progress(task_id)\n        if outputs is not None:\n            retrieve_task_results(task_id, outputs)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Notes:</p> <ul> <li>Replace <code>base_url</code> with your actual Visionatrix server URL if it's different.</li> <li>For the second example, replace <code>input_image_path</code> with the path to your input image file. Ensure that the file exists at the specified path.</li> <li>When creating a task, the API expects a <code>PUT</code> request with <code>multipart/form-data</code>. Therefore, even if you are not uploading any files (as in the <code>sdxl_lighting</code> flow), you should use <code>files=params</code> to ensure the request uses the correct content type.</li> <li>These scripts include basic error handling and polling logic.</li> <li>The <code>check_task_progress</code> function polls the task progress every 5 seconds. Adjust the sleep time as needed.</li> <li>The <code>retrieve_task_results</code> function uses the <code>outputs</code> obtained from the <code>check_task_progress</code> function, avoiding an additional call to the server.</li> <li>The result files are saved in the current working directory with filenames that include the task ID and node ID.</li> <li>Ensure that the required flows (<code>sdxl_lighting</code> and <code>remove_background_birefnet</code>) are installed on your Visionatrix instance before running these scripts.</li> <li>Additional optional parameters like <code>webhook_url</code>, <code>translate</code>, <code>group_scope</code>, <code>seed</code>, etc., are available but are not covered in this beginner guide.</li> </ul>"}]}